{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lmtw_pSbGjCY",
    "outputId": "e6f7032e-43ff-4087-e916-c2b831bad89d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "5fYVvVnPkzJk"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4_I5X_GW80eo",
    "outputId": "48e1fbbe-c08d-4eb7-db1a-5b8fa3780011"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYs2w5tERN6S",
    "tags": []
   },
   "source": [
    "## Download RAF-DB dataset (Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d0OqFiGiKzIg",
    "outputId": "279870fe-350a-4e6b-e083-5cfff3e0bf41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-29 02:12:31--  https://github.com/MegaloPat/DNN/raw/main/DNN/aligned.zip\n",
      "Resolving github.com (github.com)... 20.27.177.113\n",
      "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/MegaloPat/DNN/main/DNN/aligned.zip [following]\n",
      "--2023-01-29 02:12:32--  https://raw.githubusercontent.com/MegaloPat/DNN/main/DNN/aligned.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 39152089 (37M) [application/zip]\n",
      "Saving to: ‘aligned.zip.1’\n",
      "\n",
      "aligned.zip.1       100%[===================>]  37.34M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2023-01-29 02:12:32 (334 MB/s) - ‘aligned.zip.1’ saved [39152089/39152089]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://github.com/MegaloPat/DNN/raw/main/DNN/aligned.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRUMP23yRN6W",
    "outputId": "c16795c7-e392-4273-f7bd-76228cb21697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-29 02:12:32--  https://github.com/MegaloPat/DNN/raw/main/DNN/landmark.zip\n",
      "Resolving github.com (github.com)... 20.27.177.113\n",
      "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/MegaloPat/DNN/main/DNN/landmark.zip [following]\n",
      "--2023-01-29 02:12:33--  https://raw.githubusercontent.com/MegaloPat/DNN/main/DNN/landmark.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 86475976 (82M) [application/zip]\n",
      "Saving to: ‘landmark.zip.1’\n",
      "\n",
      "landmark.zip.1      100%[===================>]  82.47M   346MB/s    in 0.2s    \n",
      "\n",
      "2023-01-29 02:12:33 (346 MB/s) - ‘landmark.zip.1’ saved [86475976/86475976]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://github.com/MegaloPat/DNN/raw/main/DNN/landmark.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "suemGu3wRN6Y",
    "outputId": "71a5cd32-1948-4ff5-bd2f-fc5f557811cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-29 02:12:33--  https://raw.githubusercontent.com/MegaloPat/DNN/main/DNN/list_patition_label.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 285305 (279K) [text/plain]\n",
      "Saving to: ‘list_patition_label.txt.1’\n",
      "\n",
      "list_patition_label 100%[===================>] 278.62K  --.-KB/s    in 0.006s  \n",
      "\n",
      "2023-01-29 02:12:34 (44.2 MB/s) - ‘list_patition_label.txt.1’ saved [285305/285305]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://raw.githubusercontent.com/MegaloPat/DNN/main/DNN/list_patition_label.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_u6BzVPDRN6a"
   },
   "source": [
    "## Download pretrained VGG_Face weights (Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xaaP6dBLZM8",
    "outputId": "d4f97d41-031c-424f-c921-53a21428aaa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-29 02:12:34--  https://www.robots.ox.ac.uk/~albanie/models/pytorch-mcn/vgg_face_dag.pth\n",
      "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
      "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 580015466 (553M)\n",
      "Saving to: ‘vgg_face_dag.pth.1’\n",
      "\n",
      "vgg_face_dag.pth.1  100%[===================>] 553.15M  14.3MB/s    in 42s     \n",
      "\n",
      "2023-01-29 02:13:17 (13.3 MB/s) - ‘vgg_face_dag.pth.1’ saved [580015466/580015466]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://www.robots.ox.ac.uk/~albanie/models/pytorch-mcn/vgg_face_dag.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AK-qn9hFeHqA"
   },
   "source": [
    "# I - Vanilla classification with pretrained VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPuFjHO5RN6e"
   },
   "source": [
    "First we will try to get baseline results with VGG pretrained on VGG_Face without any changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFWWOXXueWol"
   },
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAljxGKMeQ0g"
   },
   "source": [
    "### Unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "5V-l3Mf6TTQq"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"aligned.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"./aligned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3hUoGmxTTQr",
    "outputId": "e23e5903-46cf-478b-ee22-6766dbea689d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘aligned/train’: File exists\n",
      "mkdir: cannot create directory ‘aligned/test’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir aligned/train\n",
    "!mkdir aligned/test\n",
    "!mv aligned/aligned/train_* aligned/train\n",
    "!mv aligned/aligned/test_* aligned/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9KfQpHqebCw"
   },
   "source": [
    "### Prepare csv labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "_gf_GRWUTTQs"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"list_patition_label.txt\",\"r\") as file :\n",
    "    train_csv = open(\"train_list_label.csv\",\"w\",newline=\"\")\n",
    "    test_csv = open(\"test_list_label.csv\",\"w\",newline=\"\")\n",
    "\n",
    "    train_writer = csv.writer(train_csv)\n",
    "    train_writer.writerow([\"Filename\", \"Label\"])\n",
    "    \n",
    "    test_writer = csv.writer(test_csv)\n",
    "    test_writer.writerow([\"Filename\", \"Label\"])\n",
    "    \n",
    "    \n",
    "    for line in file:\n",
    "        filename, label = line.strip().split(\" \")\n",
    "        idx = filename.index(\".jpg\")\n",
    "        filename = filename[:idx] + \"_aligned\" + filename[idx:]\n",
    "        label = str(int(label) - 1)\n",
    "        \n",
    "        if \"train\" in filename :\n",
    "            train_writer.writerow([filename, label])\n",
    "        else :\n",
    "            test_writer.writerow([filename, label])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTAvN8J3egfk"
   },
   "source": [
    "### Preprocessing transform\n",
    "Preprocessing is the same as the experimental protocol of the original paper. This includes :\n",
    "* Resize to 224x224\n",
    "* Random rotation of -10° +10°\n",
    "* Random horizontal flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "9MF1-iFsTTQt"
   },
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.float()),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaC7JedKenG_"
   },
   "source": [
    "### Create dataloaders\n",
    "Validation set will be sampled with a stratified split of test set, as in the paper, with ratio 50/50.\n",
    "\n",
    "Overall the proportions for the train/test/validation datasets are 80/10/10 %\n",
    "\n",
    "Finally, we will use a batch size of 16 as in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "RhF0_COyTTQv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RFB9WkgxTTQx",
    "outputId": "b33f999a-4b3a-4698-d75d-caccdf9d71ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nb batches in train: 758\n"
     ]
    }
   ],
   "source": [
    "train_data = CustomImageDataset(\"train_list_label.csv\",\"./aligned/train\", transform=trans)\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=4)\n",
    "print(f\"\\nNb batches in train: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "I2paf1E6TTQy"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_data = CustomImageDataset(\"test_list_label.csv\",\"./aligned/test\", transform=trans)\n",
    "\n",
    "test_indices, val_indices = train_test_split(list(range(len(test_data.img_labels.Label))), test_size=0.5, stratify=test_data.img_labels.Label)\n",
    "\n",
    "val_data = torch.utils.data.Subset(test_data, val_indices)\n",
    "test_data = torch.utils.data.Subset(test_data, test_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g0vmJvM_c96n",
    "outputId": "fe3e290a-37b1-43a6-9ef6-94afbdb366bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nb batches in test: 92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=True, num_workers=4)\n",
    "print(f\"\\nNb batches in test: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Cztj6-wc_iE",
    "outputId": "33836c65-6ecf-4694-a65a-36085092c02a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nb batches in val: 92\n"
     ]
    }
   ],
   "source": [
    "val_loader = DataLoader(val_data, batch_size=16, shuffle=True, num_workers=4)\n",
    "print(f\"\\nNb batches in val: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpPiJoR9ewyx"
   },
   "source": [
    "## VGG class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "RF0r5z--TTQ0"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Vgg(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Vgg, self).__init__()\n",
    "        self.meta = {'mean': [129.186279296875, 104.76238250732422, 93.59396362304688],\n",
    "                     'std': [1, 1, 1],\n",
    "                     'imageSize': [224, 224, 3]}\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu2_2 = nn.ReLU(inplace=True)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_1 = nn.ReLU(inplace=True)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_2 = nn.ReLU(inplace=True)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_3 = nn.ReLU(inplace=True)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_1 = nn.ReLU(inplace=True)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_2 = nn.ReLU(inplace=True)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_3 = nn.ReLU(inplace=True)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_1 = nn.ReLU(inplace=True)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_2 = nn.ReLU(inplace=True)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_3 = nn.ReLU(inplace=True)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
    "        self.fc6 = nn.Linear(in_features=25088, out_features=4096, bias=True)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.dropout6 = nn.Dropout(p=0.5)\n",
    "        self.fc7 = nn.Linear(in_features=4096, out_features=4096, bias=True)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.dropout7 = nn.Dropout(p=0.5)\n",
    "        self.fc8 = nn.Linear(in_features=4096, out_features=7, bias=True)\n",
    "\n",
    "\n",
    "    def forward(self, x0):\n",
    "        x1 = self.conv1_1(x0)\n",
    "        x2 = self.relu1_1(x1)\n",
    "        x3 = self.conv1_2(x2)\n",
    "        x4 = self.relu1_2(x3)\n",
    "        x5 = self.pool1(x4)\n",
    "        x6 = self.conv2_1(x5)\n",
    "        x7 = self.relu2_1(x6)\n",
    "        x8 = self.conv2_2(x7)\n",
    "        x9 = self.relu2_2(x8)\n",
    "        x10 = self.pool2(x9)\n",
    "        x11 = self.conv3_1(x10)\n",
    "        x12 = self.relu3_1(x11)\n",
    "        x13 = self.conv3_2(x12)\n",
    "        x14 = self.relu3_2(x13)\n",
    "        x15 = self.conv3_3(x14)\n",
    "        x16 = self.relu3_3(x15)\n",
    "        x17 = self.pool3(x16)\n",
    "        x18 = self.conv4_1(x17)\n",
    "        x19 = self.relu4_1(x18)\n",
    "        x20 = self.conv4_2(x19)\n",
    "        x21 = self.relu4_2(x20)\n",
    "        x22 = self.conv4_3(x21)\n",
    "        x23 = self.relu4_3(x22)\n",
    "        x24 = self.pool4(x23)\n",
    "        x25 = self.conv5_1(x24)\n",
    "        x26 = self.relu5_1(x25)\n",
    "        x27 = self.conv5_2(x26)\n",
    "        x28 = self.relu5_2(x27)\n",
    "        x29 = self.conv5_3(x28)\n",
    "        x30 = self.relu5_3(x29)\n",
    "        x31_preflatten = self.pool5(x30)\n",
    "        x31 = x31_preflatten.view(x31_preflatten.size(0), -1)\n",
    "        x32 = self.fc6(x31)\n",
    "        x33 = self.relu6(x32)\n",
    "        x34 = self.dropout6(x33)\n",
    "        x35 = self.fc7(x34)\n",
    "        x36 = self.relu7(x35)\n",
    "        x37 = self.dropout7(x36)\n",
    "        x38 = self.fc8(x37)\n",
    "        return x38\n",
    "\n",
    "def vgg_face(weights_path=None, **kwargs):\n",
    "    \"\"\"\n",
    "    load imported model instance\n",
    "\n",
    "    Args:\n",
    "        weights_path (str): If set, loads model weights from the given path\n",
    "    \"\"\"\n",
    "    model = Vgg()\n",
    "    if weights_path:\n",
    "        state_dict = torch.load(weights_path)\n",
    "        state_dict.pop(\"fc6.weight\")\n",
    "        state_dict.pop(\"fc6.bias\")\n",
    "        state_dict.pop(\"fc7.weight\")\n",
    "        state_dict.pop(\"fc7.bias\")\n",
    "        state_dict.pop(\"fc8.weight\")\n",
    "        state_dict.pop(\"fc8.bias\")\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6znD8m3e0UX"
   },
   "source": [
    "### Load pretrained weights on vgg_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "-mz1UwaITTQ1"
   },
   "outputs": [],
   "source": [
    "vgg = vgg_face(\"vgg_face_dag.pth\")\n",
    "vgg = vgg.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfE_h1R5e44U"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2Vz0Yf4e7kU"
   },
   "source": [
    "### Initial evaluation on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "qyUWv3xVg6j8"
   },
   "outputs": [],
   "source": [
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "\n",
    "def eval_model(net, loader):\n",
    "  net.eval()\n",
    "  acc, loss = 0., 0.\n",
    "  c = 0\n",
    "  for x, y in loader:\n",
    "    with torch.no_grad():\n",
    "      # No need to compute gradient here thus we avoid storing intermediary activations\n",
    "      logits = net(x.to(device)).cpu()\n",
    "\n",
    "    loss += cross_entropy(logits, y).item()\n",
    "    preds = logits.argmax(dim=1)\n",
    "    acc += (preds.numpy() == y.numpy()).sum()\n",
    "    c += len(x)\n",
    "\n",
    "  acc /= c\n",
    "  loss /= len(loader)\n",
    "  net.train()\n",
    "  return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nzWqyNeOTTQ2",
    "outputId": "2b94acf0-7e00-4ceb-e109-a0203241c959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy/loss on val: 12.57/3.0378\n"
     ]
    }
   ],
   "source": [
    "initial_acc, initial_loss = eval_model(vgg, val_loader)\n",
    "print(f\"Initial accuracy/loss on val: {round(100 * initial_acc, 2)}/{round(initial_loss, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEUMsdH-fF79"
   },
   "source": [
    "### Training\n",
    "\n",
    "Training will be performed with adam optimizer, using a base learning rate of 5e-5 and polynomial decay on all epochs with a power of 0.5, for 75 epochs.  \n",
    "We will save the best model according to the accuracy on the validation set.  \n",
    "These parameters follow the experimental protocol of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "HFqWHdsKfC_O"
   },
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import PolynomialLR\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(vgg.parameters(), lr=0.00005)\n",
    "scheduler = PolynomialLR(optimizer, total_iters=75, power=2)\n",
    "\n",
    "nb_epochs = 75\n",
    "\n",
    "train_accs, train_losses = [], []\n",
    "val_accs, val_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27MCDp2JTTQ2",
    "outputId": "f6ca9ac4-2748-4565-936c-5cf0264b3cef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:29<00:00,  3.62batch/s, loss=1.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75, train acc/loss: 42.12/1.5505, val acc/loss: 42.12/1.4842, time 219s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.57batch/s, loss=1.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/75, train acc/loss: 42.41/1.531, val acc/loss: 41.64/1.4882, time 220s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.55batch/s, loss=1.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/75, train acc/loss: 42.55/1.5294, val acc/loss: 41.78/1.4864, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/75, train acc/loss: 42.35/1.5263, val acc/loss: 42.66/1.4847, time 223s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/75, train acc/loss: 42.05/1.5286, val acc/loss: 42.19/1.4853, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/75, train acc/loss: 42.35/1.53, val acc/loss: 42.53/1.4816, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/75, train acc/loss: 41.89/1.5279, val acc/loss: 42.12/1.4834, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/75, train acc/loss: 42.09/1.5283, val acc/loss: 42.8/1.483, time 223s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/75, train acc/loss: 42.1/1.532, val acc/loss: 42.19/1.482, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/75, train acc/loss: 42.07/1.53, val acc/loss: 41.78/1.482, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/75, train acc/loss: 42.21/1.5316, val acc/loss: 41.3/1.4856, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/75, train acc/loss: 42.36/1.532, val acc/loss: 42.46/1.483, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/75, train acc/loss: 41.96/1.5301, val acc/loss: 42.39/1.4857, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/75, train acc/loss: 42.07/1.5349, val acc/loss: 42.19/1.4887, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/75, train acc/loss: 42.07/1.527, val acc/loss: 42.53/1.4848, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/75, train acc/loss: 42.21/1.5296, val acc/loss: 42.46/1.4822, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.52]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/75, train acc/loss: 42.6/1.5255, val acc/loss: 42.26/1.4803, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/75, train acc/loss: 42.15/1.5283, val acc/loss: 41.51/1.4856, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/75, train acc/loss: 42.21/1.5303, val acc/loss: 42.53/1.4842, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/75, train acc/loss: 42.4/1.5294, val acc/loss: 42.8/1.4835, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/75, train acc/loss: 42.05/1.5308, val acc/loss: 42.46/1.486, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/75, train acc/loss: 42.69/1.5231, val acc/loss: 42.53/1.4868, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/75, train acc/loss: 42.34/1.5272, val acc/loss: 42.12/1.4844, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/75, train acc/loss: 42.19/1.5256, val acc/loss: 41.78/1.4817, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/75, train acc/loss: 42.17/1.5262, val acc/loss: 42.39/1.4846, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/75, train acc/loss: 41.97/1.5308, val acc/loss: 41.92/1.4862, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/75, train acc/loss: 42.38/1.5305, val acc/loss: 42.19/1.4829, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=0.968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/75, train acc/loss: 42.49/1.5299, val acc/loss: 41.98/1.4871, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/75, train acc/loss: 42.65/1.5289, val acc/loss: 42.32/1.4868, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/75, train acc/loss: 42.23/1.532, val acc/loss: 42.66/1.4833, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/75, train acc/loss: 42.11/1.5272, val acc/loss: 42.12/1.4861, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/75, train acc/loss: 42.32/1.5291, val acc/loss: 42.46/1.4847, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/75, train acc/loss: 42.41/1.525, val acc/loss: 42.12/1.4838, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/75, train acc/loss: 42.14/1.5266, val acc/loss: 41.98/1.4833, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/75, train acc/loss: 42.26/1.5277, val acc/loss: 42.32/1.4821, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.19]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/75, train acc/loss: 42.35/1.5288, val acc/loss: 42.05/1.4852, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.92]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/75, train acc/loss: 42.25/1.5284, val acc/loss: 42.32/1.483, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.55batch/s, loss=2.24]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/75, train acc/loss: 42.29/1.5314, val acc/loss: 42.19/1.4844, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=2.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/75, train acc/loss: 42.3/1.5303, val acc/loss: 43.21/1.4815, time 223s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/75, train acc/loss: 42.57/1.5283, val acc/loss: 42.19/1.4865, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/75, train acc/loss: 42.29/1.5301, val acc/loss: 42.19/1.4795, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/75, train acc/loss: 42.26/1.5282, val acc/loss: 41.92/1.4834, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=2.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/75, train acc/loss: 42.13/1.5314, val acc/loss: 42.19/1.486, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.55batch/s, loss=1.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/75, train acc/loss: 41.82/1.5282, val acc/loss: 42.19/1.4873, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/75, train acc/loss: 42.23/1.5316, val acc/loss: 42.46/1.4846, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/75, train acc/loss: 42.39/1.5258, val acc/loss: 42.53/1.4871, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=2.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/75, train acc/loss: 42.28/1.5287, val acc/loss: 42.12/1.4856, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/75, train acc/loss: 42.28/1.5243, val acc/loss: 42.05/1.4867, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/75, train acc/loss: 42.25/1.5277, val acc/loss: 41.71/1.4841, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.55batch/s, loss=1.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/75, train acc/loss: 42.33/1.5251, val acc/loss: 42.66/1.4809, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.55batch/s, loss=1.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/75, train acc/loss: 42.17/1.5289, val acc/loss: 41.92/1.4845, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.65]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/75, train acc/loss: 42.19/1.5296, val acc/loss: 42.39/1.4865, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.55batch/s, loss=1.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/75, train acc/loss: 42.35/1.5248, val acc/loss: 42.46/1.4856, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/75, train acc/loss: 42.17/1.5288, val acc/loss: 42.26/1.4812, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.57]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/75, train acc/loss: 42.4/1.5257, val acc/loss: 42.32/1.4845, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/75, train acc/loss: 41.86/1.5316, val acc/loss: 42.05/1.485, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.81]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/75, train acc/loss: 42.36/1.5279, val acc/loss: 42.19/1.4799, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/75, train acc/loss: 42.4/1.5289, val acc/loss: 42.26/1.4823, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/75, train acc/loss: 42.45/1.5266, val acc/loss: 42.46/1.4841, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.55batch/s, loss=1.59]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/75, train acc/loss: 42.25/1.5274, val acc/loss: 42.53/1.4856, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.55batch/s, loss=1.76]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/75, train acc/loss: 42.26/1.5283, val acc/loss: 42.05/1.4864, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.55batch/s, loss=1.56]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/75, train acc/loss: 42.4/1.526, val acc/loss: 42.66/1.4862, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.55batch/s, loss=1.73]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/75, train acc/loss: 42.4/1.5266, val acc/loss: 42.26/1.4814, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/75, train acc/loss: 42.38/1.5281, val acc/loss: 42.73/1.4824, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.55batch/s, loss=1.89]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/75, train acc/loss: 41.97/1.5291, val acc/loss: 42.73/1.4798, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.85]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/75, train acc/loss: 42.5/1.53, val acc/loss: 42.39/1.4808, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.55batch/s, loss=2.03]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/75, train acc/loss: 42.13/1.5292, val acc/loss: 42.19/1.481, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/75, train acc/loss: 42.21/1.5289, val acc/loss: 42.32/1.4864, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/75, train acc/loss: 42.44/1.5299, val acc/loss: 42.39/1.4874, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:32<00:00,  3.56batch/s, loss=1.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/75, train acc/loss: 42.68/1.5285, val acc/loss: 42.32/1.4862, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/75, train acc/loss: 42.53/1.5293, val acc/loss: 42.53/1.4853, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.55batch/s, loss=1.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/75, train acc/loss: 42.38/1.5293, val acc/loss: 42.19/1.4834, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/75, train acc/loss: 42.26/1.5286, val acc/loss: 42.46/1.4853, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/75, train acc/loss: 41.88/1.5289, val acc/loss: 42.26/1.4863, time 221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [03:33<00:00,  3.56batch/s, loss=1.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/75, train acc/loss: 42.19/1.5318, val acc/loss: 41.98/1.4834, time 221s\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "best_acc = 0\n",
    "for epoch in range(nb_epochs):\n",
    "  with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "    start = time.time()\n",
    "    running_acc, running_loss = 0., 0.\n",
    "    c = 0\n",
    "    for x, y in tepoch:\n",
    "      x, y = x.to(device), y.to(device)\n",
    "\n",
    "      optimizer.zero_grad()  # Clear previous gradients\n",
    "      logits = vgg(x)\n",
    "      loss = cross_entropy(logits, y)\n",
    "      loss.backward()  # Compute gradients\n",
    "      optimizer.step()  # Update weights with gradients\n",
    "\n",
    "      running_acc += (logits.argmax(dim=1).cpu().numpy() == y.cpu().numpy()).sum()\n",
    "      running_loss += loss.item()\n",
    "      c += len(x)\n",
    "      tepoch.set_postfix(loss=loss.item())\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    train_acc, train_loss = running_acc / c, running_loss / len(train_loader)\n",
    "    train_accs.append(train_acc)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    val_acc, val_loss = eval_model(vgg, val_loader)\n",
    "    if val_acc > best_acc:\n",
    "      best_acc = val_acc\n",
    "      torch.save(vgg.state_dict(),\"vgg_best_param.pth\")\n",
    "    val_accs.append(val_acc)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}/{nb_epochs}, \"\n",
    "        f\"train acc/loss: {round(100 * train_acc, 2)}/{round(train_loss, 4)}, \"\n",
    "        f\"val acc/loss: {round(100 * val_acc, 2)}/{round(val_loss, 4)}, \"\n",
    "        f\"time {int(time.time() - start)}s\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "INtYIpmcosHw",
    "outputId": "d030dfe6-9fb0-475b-bbec-9e01e53cc854"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(list(range(nb_epochs)), train_accs, label=\"Train\")\n",
    "plt.plot(list(range(nb_epochs)), val_accs, label=\"Val\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(list(range(nb_epochs)), train_losses, label=\"Train\")\n",
    "plt.plot(list(range(nb_epochs)), val_losses, label=\"Val\")\n",
    "plt.title(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ry9hgujofKMO"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tu_xXdYLR-GQ",
    "outputId": "bc81e813-d639-41c5-aefb-fb5a4637026f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"vgg_best_param.pth\")\n",
    "vgg.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "939OxVuZJsCc",
    "outputId": "38773c55-59bd-449f-ba2b-d50fd9c29fcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4221617946974847, 1.4787118175755376)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc, test_loss = eval_model(vgg, test_loader)\n",
    "test_acc, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OF-ecOeESOBK"
   },
   "source": [
    "# II - Vgg with Pal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2aQp6olaRN6z"
   },
   "source": [
    "Now we will train to reproduce the best results of the paper using PAL. Consequently, we will use PAL on the 15th layer, with Grad\\*Input as attribution map and the half mean channel strategy. The other parameters will follow the paper, and thus will not change compared to part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzPD9cMvRN6z"
   },
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIDGdf9YRN60"
   },
   "source": [
    "### Unzip priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "TQmFZkQvSeuT"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"landmark.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"./landmark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "69CmLPTeSurv",
    "outputId": "27f09b64-af90-44ae-fe13-d401edb2236e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘landmark/train’: File exists\n",
      "mkdir: cannot create directory ‘landmark/test’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir landmark/train\n",
    "!mkdir landmark/test\n",
    "!mv landmark/landmark/train_* landmark/train\n",
    "!mv landmark/landmark/test_* landmark/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mluVQasYRN61"
   },
   "source": [
    "### Create dataloaders\n",
    "The process is the same as in part I, with the added priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "Ulx3aSxCS_3z"
   },
   "outputs": [],
   "source": [
    "class JoinImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, landmark_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.landmark_dir = landmark_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        land_path = os.path.join(self.landmark_dir, self.img_labels.iloc[idx, 0])\n",
    "        landmark = read_image(land_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, landmark, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P78LHeOuTjm3",
    "outputId": "336031bb-8180-48a7-b532-d420bcdaa4d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nb batches in train: 767\n"
     ]
    }
   ],
   "source": [
    "train_data = JoinImageDataset(\"train_list_label.csv\",\"./aligned/train\", \"./landmark/train\", transform=trans)\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=4)\n",
    "print(f\"\\nNb batches in train: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "Nv1zFNLcT4xW"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_data = JoinImageDataset(\"test_list_label.csv\",\"./aligned/test\",\"./landmark/test\", transform=trans)\n",
    "\n",
    "test_indices, val_indices = train_test_split(list(range(len(test_data.img_labels.Label))), test_size=0.5, stratify=test_data.img_labels.Label)\n",
    "\n",
    "val_data = torch.utils.data.Subset(test_data, val_indices)\n",
    "test_data = torch.utils.data.Subset(test_data, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SCcVeomlUEx3",
    "outputId": "c341fe07-169d-4642-ae1a-ea0661b5183e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nb batches in test: 96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=True, num_workers=4)\n",
    "print(f\"\\nNb batches in test: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SlqNHILrUKMw",
    "outputId": "635f8367-424b-447f-cc6e-e9870fa75847"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nb batches in val: 96\n"
     ]
    }
   ],
   "source": [
    "val_loader = DataLoader(val_data, batch_size=16, shuffle=True, num_workers=4)\n",
    "print(f\"\\nNb batches in val: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJNbYN58RN64"
   },
   "source": [
    "## Modified Vgg class\n",
    "The class now outputs input and output of layer 15 in order to apply PAL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "UOSjJUATUOx4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class VggPal(Vgg):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VggPal, self).__init__()\n",
    "  \n",
    "    def forward(self, x0):\n",
    "        x1 = self.conv1_1(x0)\n",
    "        x2 = self.relu1_1(x1)\n",
    "        x3 = self.conv1_2(x2)\n",
    "        x4 = self.relu1_2(x3)\n",
    "        x5 = self.pool1(x4)\n",
    "        x6 = self.conv2_1(x5)\n",
    "        x7 = self.relu2_1(x6)\n",
    "        x8 = self.conv2_2(x7)\n",
    "        x9 = self.relu2_2(x8)\n",
    "        x10 = self.pool2(x9)\n",
    "        x11 = self.conv3_1(x10)\n",
    "        x12 = self.relu3_1(x11)\n",
    "        x13 = self.conv3_2(x12)\n",
    "        x14 = self.relu3_2(x13)\n",
    "        x15 = self.conv3_3(x14)\n",
    "        x16 = self.relu3_3(x15)\n",
    "        x17 = self.pool3(x16)\n",
    "        x18 = self.conv4_1(x17)\n",
    "        x19 = self.relu4_1(x18)\n",
    "        x20 = self.conv4_2(x19)\n",
    "        x21 = self.relu4_2(x20)\n",
    "        x22 = self.conv4_3(x21)\n",
    "        x23 = self.relu4_3(x22)\n",
    "        x24 = self.pool4(x23)\n",
    "        x25 = self.conv5_1(x24)\n",
    "        x26 = self.relu5_1(x25)\n",
    "        x27 = self.conv5_2(x26)\n",
    "        x28 = self.relu5_2(x27)\n",
    "        x29 = self.conv5_3(x28)\n",
    "        x30 = self.relu5_3(x29)\n",
    "        x31_preflatten = self.pool5(x30)\n",
    "        x31 = x31_preflatten.view(x31_preflatten.size(0), -1)\n",
    "        x32 = self.fc6(x31)\n",
    "        x33 = self.relu6(x32)\n",
    "        x34 = self.dropout6(x33)\n",
    "        x35 = self.fc7(x34)\n",
    "        x36 = self.relu7(x35)\n",
    "        x37 = self.dropout7(x36)\n",
    "        x38 = self.fc8(x37)\n",
    "        \n",
    "        return x24,x25,x38\n",
    "\n",
    "def vggpal_face(weights_path=None, **kwargs):\n",
    "    \"\"\"\n",
    "    load imported model instance\n",
    "\n",
    "    Args:\n",
    "        weights_path (str): If set, loads model weights from the given path\n",
    "    \"\"\"\n",
    "    model = VggPal()\n",
    "    if weights_path:\n",
    "        state_dict = torch.load(weights_path)\n",
    "        state_dict.pop(\"fc6.weight\")\n",
    "        state_dict.pop(\"fc6.bias\")\n",
    "        state_dict.pop(\"fc7.weight\")\n",
    "        state_dict.pop(\"fc7.bias\")\n",
    "        state_dict.pop(\"fc8.weight\")\n",
    "        state_dict.pop(\"fc8.bias\")\n",
    "        model.load_state_dict(state_dict, strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmsBDlm4RN65"
   },
   "source": [
    "### Load pretrained weights on vgg_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "pJKrhFKVVgQM"
   },
   "outputs": [],
   "source": [
    "vggpal = vggpal_face(\"vgg_face_dag.pth\")\n",
    "vggpal = vggpal.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dc_emjARRN66"
   },
   "source": [
    "## Definition of PAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "gjeV_zDwZHx8"
   },
   "outputs": [],
   "source": [
    "def Grad(inputs, outputs) :\n",
    "    outputs_sum = outputs.sum()\n",
    "    inputs.retain_grad()\n",
    "    outputs.retain_grad()\n",
    "    outputs_sum.backward(retain_graph=True)\n",
    "    return torch.abs(inputs.grad)\n",
    "\n",
    "def GradxInput(inputs, outputs) :\n",
    "    Grad_val = Grad(inputs, outputs)\n",
    "    return Grad_val * inputs\n",
    "\n",
    "def PAL(inputs, outputs, prior, attribution_method, channel_strategy=None) :\n",
    "    attribution_map = attribution_method(inputs, outputs)\n",
    "    \n",
    "    if channel_strategy == \"half_mean\" :\n",
    "        nb_class = attribution_map.shape[1]\n",
    "        attribution_map[:, int(nb_class/2):, :, :]\n",
    "    \n",
    "    if channel_strategy == \"half_mean\" or channel_strategy == \"mean\" :\n",
    "        attribution_map = attribution_map.mean(1).unsqueeze(1)\n",
    "    \n",
    "    attribution_map_resize = transforms.Resize(attribution_map.shape[-2:])\n",
    "    \n",
    "    prior = attribution_map_resize(prior)\n",
    "    \n",
    "    std = attribution_map.view(attribution_map.size(0), -1).std(1)\n",
    "    mean = attribution_map.view(attribution_map.size(0), -1).mean(1)\n",
    "    \n",
    "    \n",
    "    res = (attribution_map - mean.view(-1, 1, 1, 1)) / std.view(-1, 1, 1, 1)\n",
    "    res = res * prior.unsqueeze(1)\n",
    "    \n",
    "    res = res.view(res.size(0), -1).sum(1)\n",
    "    res = -res\n",
    "    return res.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "puU0EGIdZOjx"
   },
   "outputs": [],
   "source": [
    "def tot_loss(li, lo, prior, logits, y):\n",
    "    pa_loss = PAL(li, lo, prior, GradxInput, \"half_mean\")\n",
    "    ce_loss = cross_entropy(logits, y)\n",
    "    return pa_loss + ce_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJQ48Q0_RN68"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCv9Db4MRN69"
   },
   "source": [
    "### Initial evaluation on validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "FOqWGhSqZBDc"
   },
   "outputs": [],
   "source": [
    "def eval_modelpal(net, loader):\n",
    "  net.eval()\n",
    "  acc, loss = 0., 0.\n",
    "  c = 0\n",
    "  for x, prior, y in loader:\n",
    "    x, prior, y = x.to(device), prior.to(device),y.to(device)\n",
    "    li, lo, logits = net(x.to(device))\n",
    "    loss += tot_loss(li, lo, prior, logits, y).item()\n",
    "    preds = logits.argmax(dim=1)\n",
    "    acc += (preds.cpu().numpy() == y.cpu().numpy()).sum()\n",
    "    c += len(x)\n",
    "\n",
    "  acc /= c\n",
    "  loss /= len(loader)\n",
    "  net.train()\n",
    "  return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UYNlujThVo6i",
    "outputId": "f0f6579d-9ba3-4aa7-d679-fd68157323ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial accuracy/loss on val: 25.36/40341.8236\n"
     ]
    }
   ],
   "source": [
    "initial_acc, initial_loss = eval_modelpal(vggpal, val_loader)\n",
    "print(f\"Initial accuracy/loss on val: {round(100 * initial_acc, 2)}/{round(initial_loss, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PisThvfWRN6-"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "itbzcRpwV9Lb"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(vggpal.parameters(), lr=0.00005)\n",
    "scheduler = PolynomialLR(optimizer, total_iters=75, power=2)\n",
    "\n",
    "nb_epochs = 75\n",
    "\n",
    "train_accs, train_losses = [], []\n",
    "val_accs, val_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5f7XGWyWGZ1",
    "outputId": "af37e3d6-2b24-4db1-c852-ccad8a146640"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [05:13<00:00,  2.45batch/s, loss=9.31e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75, train acc/loss: 38.77/92826.6236, val acc/loss: 38.59/90788.7556, time 336s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [05:13<00:00,  2.45batch/s, loss=7.7e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/75, train acc/loss: 38.91/91588.1951, val acc/loss: 38.59/91349.7791, time 334s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [05:13<00:00,  2.45batch/s, loss=8.54e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/75, train acc/loss: 38.86/91583.1396, val acc/loss: 38.59/91956.8169, time 334s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [05:13<00:00,  2.45batch/s, loss=8.86e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/75, train acc/loss: 38.88/91836.8825, val acc/loss: 38.59/92087.8805, time 334s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [05:13<00:00,  2.45batch/s, loss=9.28e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/75, train acc/loss: 38.89/91725.0407, val acc/loss: 38.59/91027.6633, time 334s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [05:13<00:00,  2.45batch/s, loss=8.92e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/75, train acc/loss: 38.86/91587.4653, val acc/loss: 38.59/91490.6176, time 334s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [05:13<00:00,  2.45batch/s, loss=8.37e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/75, train acc/loss: 38.9/91802.0658, val acc/loss: 38.59/90996.9875, time 334s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [05:13<00:00,  2.44batch/s, loss=9.05e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/75, train acc/loss: 38.86/91982.7924, val acc/loss: 38.59/91327.6587, time 334s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [05:13<00:00,  2.44batch/s, loss=8.87e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/75, train acc/loss: 38.92/91768.6697, val acc/loss: 38.59/91635.3411, time 334s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [05:14<00:00,  2.44batch/s, loss=8.51e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/75, train acc/loss: 38.9/91817.9431, val acc/loss: 38.59/91605.0011, time 334s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [05:14<00:00,  2.44batch/s, loss=1.06e+5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/75, train acc/loss: 38.89/91710.9766, val acc/loss: 38.59/91369.2567, time 335s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [05:14<00:00,  2.44batch/s, loss=9.07e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/75, train acc/loss: 38.9/91896.9998, val acc/loss: 38.59/91639.8052, time 335s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [05:14<00:00,  2.44batch/s, loss=7.81e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/75, train acc/loss: 38.88/91562.4983, val acc/loss: 38.59/91141.4811, time 334s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 767/767 [05:14<00:00,  2.44batch/s, loss=8.21e+4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/75, train acc/loss: 38.91/91854.6084, val acc/loss: 38.59/91688.7273, time 335s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 185/767 [01:15<03:57,  2.45batch/s, loss=1.01e+5]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "best_acc = 0\n",
    "for epoch in range(nb_epochs):\n",
    "  with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "    start = time.time()\n",
    "    running_acc, running_loss = 0., 0.\n",
    "    c = 0\n",
    "    for x, prior, y in tepoch:\n",
    "      x, prior, y = x.to(device), prior.to(device),y.to(device)\n",
    "\n",
    "      optimizer.zero_grad()  # Clear previous gradients\n",
    "      li, lo ,logits = vggpal(x)\n",
    "      loss = tot_loss(li, lo, prior, logits, y)\n",
    "      loss.backward()  # Compute gradients\n",
    "      optimizer.step()  # Update weights with gradients\n",
    "\n",
    "      running_acc += (logits.argmax(dim=1).cpu().numpy() == y.cpu().numpy()).sum()\n",
    "      running_loss += loss.item()\n",
    "      c += len(x)\n",
    "      tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    train_acc, train_loss = running_acc / c, running_loss / len(train_loader)\n",
    "    train_accs.append(train_acc)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    val_acc, val_loss = eval_modelpal(vggpal, val_loader)\n",
    "    if val_acc > best_acc:\n",
    "      best_acc = val_acc\n",
    "      torch.save(vggpal.state_dict(),\"vggpal_best_param.pth\")\n",
    "    val_accs.append(val_acc)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch + 1}/{nb_epochs}, \"\n",
    "        f\"train acc/loss: {round(100 * train_acc, 2)}/{round(train_loss, 4)}, \"\n",
    "        f\"val acc/loss: {round(100 * val_acc, 2)}/{round(val_loss, 4)}, \"\n",
    "        f\"time {int(time.time() - start)}s\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c3DdRcYgXx5H"
   },
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(list(range(nb_epochs)), train_accs, label=\"Train\")\n",
    "plt.plot(list(range(nb_epochs)), val_accs, label=\"Val\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(list(range(nb_epochs)), train_losses, label=\"Train\")\n",
    "plt.plot(list(range(nb_epochs)), val_losses, label=\"Val\")\n",
    "plt.title(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiizdxWxRN7B"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdM_4qN_X0T3"
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"vggpal_best_param.pth\")\n",
    "vgg.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OwF7dnQX4Lt"
   },
   "outputs": [],
   "source": [
    "test_acc, test_loss = eval_modelpal(vgg, test_loader)\n",
    "test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1FVH7rsTEKp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
