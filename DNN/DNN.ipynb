{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Lmtw_pSbGjCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "157029d4-c2f5-4cfd-869d-f4aa97eae851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "%pylab inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5fYVvVnPkzJk"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4_I5X_GW80eo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00bfe05c-1480-4df0-a8fa-a76c613123ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I - Vanilla classification with pretrained VGG"
      ],
      "metadata": {
        "id": "AK-qn9hFeHqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget \"https://github.com/MegaloPat/DNN/blob/main/DNN/aligned.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0OqFiGiKzIg",
        "outputId": "b7adb430-6fda-4b2b-fe9b-3db3c0c56afc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-27 21:43:48--  https://github.com/MegaloPat/DNN/blob/main/DNN/aligned.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘aligned.zip’\n",
            "\n",
            "aligned.zip             [ <=>                ] 132.50K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-01-27 21:43:48 (12.1 MB/s) - ‘aligned.zip’ saved [135684]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://www.robots.ox.ac.uk/~albanie/models/pytorch-mcn/vgg_face_dag.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xaaP6dBLZM8",
        "outputId": "7b14f48e-05a3-4982-d89b-4d86e92e4218"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-27 21:42:37--  https://www.robots.ox.ac.uk/~albanie/models/pytorch-mcn/vgg_face_dag.pth\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 580015466 (553M)\n",
            "Saving to: ‘vgg_face_dag.pth’\n",
            "\n",
            "vgg_face_dag.pth    100%[===================>] 553.15M  14.3MB/s    in 41s     \n",
            "\n",
            "2023-01-27 21:43:19 (13.5 MB/s) - ‘vgg_face_dag.pth’ saved [580015466/580015466]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare dataset"
      ],
      "metadata": {
        "id": "EFWWOXXueWol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unzip data"
      ],
      "metadata": {
        "id": "CAljxGKMeQ0g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5V-l3Mf6TTQq"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"aligned.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./aligned\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "j3hUoGmxTTQr"
      },
      "outputs": [],
      "source": [
        "!mkdir aligned/train\n",
        "!mkdir aligned/test\n",
        "!mv aligned/aligned/train_* aligned/train\n",
        "!mv aligned/aligned/test_* aligned/test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare csv labels"
      ],
      "metadata": {
        "id": "u9KfQpHqebCw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_gf_GRWUTTQs"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "# Creation des labels sous formats csv\n",
        "\n",
        "with open(\"list_patition_label.txt\",\"r\") as file :\n",
        "    train_csv = open(\"train_list_label.csv\",\"w\",newline=\"\")\n",
        "    test_csv = open(\"test_list_label.csv\",\"w\",newline=\"\")\n",
        "\n",
        "    train_writer = csv.writer(train_csv)\n",
        "    train_writer.writerow([\"Filename\", \"Label\"])\n",
        "    \n",
        "    test_writer = csv.writer(test_csv)\n",
        "    test_writer.writerow([\"Filename\", \"Label\"])\n",
        "    \n",
        "    \n",
        "    for line in file:\n",
        "        filename, label = line.strip().split(\" \")\n",
        "        idx = filename.index(\".jpg\")\n",
        "        filename = filename[:idx] + \"_aligned\" + filename[idx:]\n",
        "        label = str(int(label) - 1)\n",
        "        \n",
        "        if \"train\" in filename :\n",
        "            train_writer.writerow([filename, label])\n",
        "        else :\n",
        "            test_writer.writerow([filename, label])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing transform"
      ],
      "metadata": {
        "id": "LTAvN8J3egfk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9MF1-iFsTTQt"
      },
      "outputs": [],
      "source": [
        "trans = transforms.Compose([\n",
        "    transforms.Lambda(lambda x: x.float()),\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip()\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create dataloaders (split is train/test/val = 80/10/10)"
      ],
      "metadata": {
        "id": "KaC7JedKenG_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "RhF0_COyTTQv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFB9WkgxTTQx",
        "outputId": "eada08fa-23aa-46c5-d269-20d36cdb0145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nb batches in train: 758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "train_data = CustomImageDataset(\"train_list_label.csv\",\"./aligned/train\", transform=trans)\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=4)\n",
        "print(f\"\\nNb batches in train: {len(train_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "I2paf1E6TTQy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "test_data = CustomImageDataset(\"test_list_label.csv\",\"./aligned/test\", transform=trans)\n",
        "\n",
        "test_indices, val_indices = train_test_split(list(range(len(test_data.img_labels.Label))), test_size=0.5, stratify=test_data.img_labels.Label)\n",
        "\n",
        "val_data = torch.utils.data.Subset(test_data, val_indices)\n",
        "test_data = torch.utils.data.Subset(test_data, test_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_data, batch_size=16, shuffle=True, num_workers=4)\n",
        "print(f\"\\nNb batches in test: {len(test_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0vmJvM_c96n",
        "outputId": "660aef5a-f8d8-49cf-d0a4-8a44ea502e62"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nb batches in test: 92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = DataLoader(val_data, batch_size=16, shuffle=True, num_workers=4)\n",
        "print(f\"\\nNb batches in val: {len(val_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Cztj6-wc_iE",
        "outputId": "8df05571-12cf-4acc-99d3-114128ad9ea1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nb batches in val: 92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG class"
      ],
      "metadata": {
        "id": "XpPiJoR9ewyx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "RF0r5z--TTQ0"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Vgg(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Vgg, self).__init__()\n",
        "        self.meta = {'mean': [129.186279296875, 104.76238250732422, 93.59396362304688],\n",
        "                     'std': [1, 1, 1],\n",
        "                     'imageSize': [224, 224, 3]}\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu1_1 = nn.ReLU(inplace=True)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu1_2 = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu2_1 = nn.ReLU(inplace=True)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu2_2 = nn.ReLU(inplace=True)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu3_1 = nn.ReLU(inplace=True)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu3_2 = nn.ReLU(inplace=True)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu3_3 = nn.ReLU(inplace=True)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu4_1 = nn.ReLU(inplace=True)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu4_2 = nn.ReLU(inplace=True)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu4_3 = nn.ReLU(inplace=True)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu5_1 = nn.ReLU(inplace=True)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu5_2 = nn.ReLU(inplace=True)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu5_3 = nn.ReLU(inplace=True)\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
        "        self.fc6 = nn.Linear(in_features=25088, out_features=4096, bias=True)\n",
        "        self.relu6 = nn.ReLU(inplace=True)\n",
        "        self.dropout6 = nn.Dropout(p=0.5)\n",
        "        self.fc7 = nn.Linear(in_features=4096, out_features=4096, bias=True)\n",
        "        self.relu7 = nn.ReLU(inplace=True)\n",
        "        self.dropout7 = nn.Dropout(p=0.5)\n",
        "        self.fc8 = nn.Linear(in_features=4096, out_features=2622, bias=True)\n",
        "\n",
        "    def forward(self, x0):\n",
        "        x1 = self.conv1_1(x0)\n",
        "        x2 = self.relu1_1(x1)\n",
        "        x3 = self.conv1_2(x2)\n",
        "        x4 = self.relu1_2(x3)\n",
        "        x5 = self.pool1(x4)\n",
        "        x6 = self.conv2_1(x5)\n",
        "        x7 = self.relu2_1(x6)\n",
        "        x8 = self.conv2_2(x7)\n",
        "        x9 = self.relu2_2(x8)\n",
        "        x10 = self.pool2(x9)\n",
        "        x11 = self.conv3_1(x10)\n",
        "        x12 = self.relu3_1(x11)\n",
        "        x13 = self.conv3_2(x12)\n",
        "        x14 = self.relu3_2(x13)\n",
        "        x15 = self.conv3_3(x14)\n",
        "        x16 = self.relu3_3(x15)\n",
        "        x17 = self.pool3(x16)\n",
        "        x18 = self.conv4_1(x17)\n",
        "        x19 = self.relu4_1(x18)\n",
        "        x20 = self.conv4_2(x19)\n",
        "        x21 = self.relu4_2(x20)\n",
        "        x22 = self.conv4_3(x21)\n",
        "        x23 = self.relu4_3(x22)\n",
        "        x24 = self.pool4(x23)\n",
        "        x25 = self.conv5_1(x24)\n",
        "        x26 = self.relu5_1(x25)\n",
        "        x27 = self.conv5_2(x26)\n",
        "        x28 = self.relu5_2(x27)\n",
        "        x29 = self.conv5_3(x28)\n",
        "        x30 = self.relu5_3(x29)\n",
        "        x31_preflatten = self.pool5(x30)\n",
        "        x31 = x31_preflatten.view(x31_preflatten.size(0), -1)\n",
        "        x32 = self.fc6(x31)\n",
        "        x33 = self.relu6(x32)\n",
        "        x34 = self.dropout6(x33)\n",
        "        x35 = self.fc7(x34)\n",
        "        x36 = self.relu7(x35)\n",
        "        x37 = self.dropout7(x36)\n",
        "        x38 = self.fc8(x37)\n",
        "        return x38\n",
        "\n",
        "def vgg_face(weights_path=None, **kwargs):\n",
        "    \"\"\"\n",
        "    load imported model instance\n",
        "\n",
        "    Args:\n",
        "        weights_path (str): If set, loads model weights from the given path\n",
        "    \"\"\"\n",
        "    model = Vgg()\n",
        "    if weights_path:\n",
        "        state_dict = torch.load(weights_path)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load pretrained weights on vgg_face"
      ],
      "metadata": {
        "id": "L6znD8m3e0UX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "-mz1UwaITTQ1"
      },
      "outputs": [],
      "source": [
        "vgg = vgg_face(\"vgg_face_dag.pth\")\n",
        "vgg.fc8 = nn.Linear(in_features=4096, out_features=7, bias=True)\n",
        "vgg = vgg.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "rfE_h1R5e44U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initial evaluation on val dataset"
      ],
      "metadata": {
        "id": "F2Vz0Yf4e7kU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "qyUWv3xVg6j8"
      },
      "outputs": [],
      "source": [
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "def eval_model(net, loader):\n",
        "  net.eval()\n",
        "  acc, loss = 0., 0.\n",
        "  c = 0\n",
        "  for x, y in loader:\n",
        "    with torch.no_grad():\n",
        "      # No need to compute gradient here thus we avoid storing intermediary activations\n",
        "      \n",
        "      logits = net(x.to(device)).cpu()\n",
        "\n",
        "    loss += cross_entropy(logits, y).item()\n",
        "    preds = logits.argmax(dim=1)\n",
        "    acc += (preds.numpy() == y.numpy()).sum()\n",
        "    c += len(x)\n",
        "    break\n",
        "\n",
        "  acc /= c\n",
        "  loss /= len(loader)\n",
        "  net.train()\n",
        "  return acc, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "nzWqyNeOTTQ2",
        "outputId": "8b5bf9d4-a3e9-4e9e-fbf7-ae8c66c5f1b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-ca7593c16a03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minitial_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Initial accuracy/loss on val: {round(100 * initial_acc, 2)}/{round(initial_loss, 4)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-a2738320c5a1>\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(net, loader)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0;31m# No need to compute gradient here thus we avoid storing intermediary activations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "initial_acc, initial_loss = eval_model(vgg, val_loader)\n",
        "print(f\"Initial accuracy/loss on val: {round(100 * initial_acc, 2)}/{round(initial_loss, 4)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "aEUMsdH-fF79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import PolynomialLR\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(vgg.parameters(), lr=0.00005)\n",
        "scheduler = PolynomialLR(optimizer, total_iters=75, power=1.0)\n",
        "\n",
        "nb_epochs = 75\n",
        "\n",
        "train_accs, train_losses = [], []\n",
        "val_accs, val_losses = [], []"
      ],
      "metadata": {
        "id": "HFqWHdsKfC_O"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        },
        "id": "27MCDp2JTTQ2",
        "outputId": "6910f8b4-989b-4db6-a4b0-66b44da004d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.44batch/s, loss=1.12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75, train acc/loss: 48.54/1.4031, val acc/loss: 68.75/0.0096, time 224s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=1.23]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/75, train acc/loss: 49.32/1.3716, val acc/loss: 56.25/0.0135, time 220s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=1.46]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/75, train acc/loss: 49.06/1.3741, val acc/loss: 31.25/0.0164, time 221s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=1.19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/75, train acc/loss: 48.95/1.3735, val acc/loss: 56.25/0.0143, time 220s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=1.22]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/75, train acc/loss: 49.37/1.3782, val acc/loss: 43.75/0.0203, time 220s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.44batch/s, loss=1.31]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/75, train acc/loss: 49.01/1.3786, val acc/loss: 68.75/0.0118, time 221s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.43batch/s, loss=1.95]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/75, train acc/loss: 49.29/1.3739, val acc/loss: 68.75/0.0101, time 221s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:38<00:00,  3.46batch/s, loss=0.752]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/75, train acc/loss: 49.36/1.375, val acc/loss: 75.0/0.016, time 221s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 18/758 [00:05<04:02,  3.05batch/s, loss=1.52]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-01e2e95f0c23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0mrunning_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m       \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "best_acc = 0\n",
        "for epoch in range(nb_epochs):\n",
        "  with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "    start = time.time()\n",
        "    running_acc, running_loss = 0., 0.\n",
        "    c = 0\n",
        "    for x, y in tepoch:\n",
        "      x, y = x.to(device), y.to(device)\n",
        "\n",
        "      optimizer.zero_grad()  # Clear previous gradients\n",
        "      logits = vgg(x)\n",
        "      loss = cross_entropy(logits, y)\n",
        "      loss.backward()  # Compute gradients\n",
        "      optimizer.step()  # Update weights with gradients\n",
        "      scheduler.step()\n",
        "\n",
        "      running_acc += (logits.argmax(dim=1).cpu().numpy() == y.cpu().numpy()).sum()\n",
        "      running_loss += loss.item()\n",
        "      c += len(x)\n",
        "      tepoch.set_postfix(loss=loss.item())\n",
        "\n",
        "    train_acc, train_loss = running_acc / c, running_loss / len(train_loader)\n",
        "    train_accs.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "    \n",
        "    val_acc, val_loss = eval_model(vgg, val_loader, cross_entropy)\n",
        "    if val_acc > best_acc:\n",
        "      best_acc = val_acc\n",
        "      torch.save(vgg.state_dict(),\"vgg_best_param.pth\")\n",
        "    val_accs.append(val_acc)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1}/{nb_epochs}, \"\n",
        "        f\"train acc/loss: {round(100 * train_acc, 2)}/{round(train_loss, 4)}, \"\n",
        "        f\"val acc/loss: {round(100 * val_acc, 2)}/{round(val_loss, 4)}, \"\n",
        "        f\"time {int(time.time() - start)}s\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INtYIpmcosHw"
      },
      "outputs": [],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(list(range(nb_epochs)), train_accs, label=\"Train\")\n",
        "plt.plot(list(range(nb_epochs)), val_accs, label=\"Val\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(list(range(nb_epochs)), train_losses, label=\"Train\")\n",
        "plt.plot(list(range(nb_epochs)), val_losses, label=\"Val\")\n",
        "plt.title(\"Loss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "ry9hgujofKMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load(\"vgg_best_param.pth\")\n",
        "vgg.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "Tu_xXdYLR-GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "939OxVuZJsCc"
      },
      "outputs": [],
      "source": [
        "test_acc, test_loss = eval_model(vgg, test_loader, cross_entropy)\n",
        "test_acc, test_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II - Vgg with Pal\n"
      ],
      "metadata": {
        "id": "OF-ecOeESOBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"landmark.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./landmark\")"
      ],
      "metadata": {
        "id": "TQmFZkQvSeuT"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir landmark/train\n",
        "!mkdir landmark/test\n",
        "!mv landmark/landmark/train_* landmark/train\n",
        "!mv landmark/landmark/test_* landmark/test"
      ],
      "metadata": {
        "id": "69CmLPTeSurv"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class JoinImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, landmark_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.landmark_dir = landmark_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        land_path = os.path.join(self.landmark_dir, self.img_labels.iloc[idx, 0])\n",
        "        landmark = read_image(land_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, landmark, label"
      ],
      "metadata": {
        "id": "Ulx3aSxCS_3z"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = JoinImageDataset(\"train_list_label.csv\",\"./aligned/train\", \"./landmark/train\", transform=trans)\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=4)\n",
        "print(f\"\\nNb batches in train: {len(train_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P78LHeOuTjm3",
        "outputId": "9d035d48-9cb6-41df-814f-9b00642b266c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nb batches in train: 758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "test_data = JoinImageDataset(\"test_list_label.csv\",\"./aligned/test\",\"./landmark/test\", transform=trans)\n",
        "\n",
        "test_indices, val_indices = train_test_split(list(range(len(test_data.img_labels.Label))), test_size=0.5, stratify=test_data.img_labels.Label)\n",
        "\n",
        "val_data = torch.utils.data.Subset(test_data, val_indices)\n",
        "test_data = torch.utils.data.Subset(test_data, test_indices)"
      ],
      "metadata": {
        "id": "Nv1zFNLcT4xW"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = DataLoader(test_data, batch_size=16, shuffle=True, num_workers=4)\n",
        "print(f\"\\nNb batches in test: {len(test_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46847fe-6d4d-4c97-c9be-4a0125cd141e",
        "id": "SCcVeomlUEx3"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nb batches in test: 92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = DataLoader(val_data, batch_size=16, shuffle=True, num_workers=4)\n",
        "print(f\"\\nNb batches in val: {len(val_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlqNHILrUKMw",
        "outputId": "cae9fb2f-4d78-42ee-ae55-2f2f319d0d36"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nb batches in val: 92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class VggPal(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(VggPal, self).__init__()\n",
        "        self.meta = {'mean': [129.186279296875, 104.76238250732422, 93.59396362304688],\n",
        "                     'std': [1, 1, 1],\n",
        "                     'imageSize': [224, 224, 3]}\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu1_1 = nn.ReLU(inplace=True)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu1_2 = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu2_1 = nn.ReLU(inplace=True)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu2_2 = nn.ReLU(inplace=True)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu3_1 = nn.ReLU(inplace=True)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu3_2 = nn.ReLU(inplace=True)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu3_3 = nn.ReLU(inplace=True)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu4_1 = nn.ReLU(inplace=True)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu4_2 = nn.ReLU(inplace=True)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu4_3 = nn.ReLU(inplace=True)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu5_1 = nn.ReLU(inplace=True)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu5_2 = nn.ReLU(inplace=True)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu5_3 = nn.ReLU(inplace=True)\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
        "        self.fc6 = nn.Linear(in_features=25088, out_features=4096, bias=True)\n",
        "        self.relu6 = nn.ReLU(inplace=True)\n",
        "        self.dropout6 = nn.Dropout(p=0.5)\n",
        "        self.fc7 = nn.Linear(in_features=4096, out_features=4096, bias=True)\n",
        "        self.relu7 = nn.ReLU(inplace=True)\n",
        "        self.dropout7 = nn.Dropout(p=0.5)\n",
        "        self.fc8 = nn.Linear(in_features=4096, out_features=2622, bias=True)\n",
        "        \n",
        "    def forward(self, x0):\n",
        "        x1 = self.conv1_1(x0)\n",
        "        x2 = self.relu1_1(x1)\n",
        "        x3 = self.conv1_2(x2)\n",
        "        x4 = self.relu1_2(x3)\n",
        "        x5 = self.pool1(x4)\n",
        "        x6 = self.conv2_1(x5)\n",
        "        x7 = self.relu2_1(x6)\n",
        "        x8 = self.conv2_2(x7)\n",
        "        x9 = self.relu2_2(x8)\n",
        "        x10 = self.pool2(x9)\n",
        "        x11 = self.conv3_1(x10)\n",
        "        x12 = self.relu3_1(x11)\n",
        "        x13 = self.conv3_2(x12)\n",
        "        x14 = self.relu3_2(x13)\n",
        "        x15 = self.conv3_3(x14)\n",
        "        x16 = self.relu3_3(x15)\n",
        "        x17 = self.pool3(x16)\n",
        "        x18 = self.conv4_1(x17)\n",
        "        x19 = self.relu4_1(x18)\n",
        "        x20 = self.conv4_2(x19)\n",
        "        x21 = self.relu4_2(x20)\n",
        "        x22 = self.conv4_3(x21)\n",
        "        x23 = self.relu4_3(x22)\n",
        "        x24 = self.pool4(x23)\n",
        "        x25 = self.conv5_1(x24)\n",
        "        x26 = self.relu5_1(x25)\n",
        "        x27 = self.conv5_2(x26)\n",
        "        x28 = self.relu5_2(x27)\n",
        "        x29 = self.conv5_3(x28)\n",
        "        x30 = self.relu5_3(x29)\n",
        "        x31_preflatten = self.pool5(x30)\n",
        "        x31 = x31_preflatten.view(x31_preflatten.size(0), -1)\n",
        "        x32 = self.fc6(x31)\n",
        "        x33 = self.relu6(x32)\n",
        "        x34 = self.dropout6(x33)\n",
        "        x35 = self.fc7(x34)\n",
        "        x36 = self.relu7(x35)\n",
        "        x37 = self.dropout7(x36)\n",
        "        x38 = self.fc8(x37)\n",
        "        return x24,x25,x38\n",
        "\n",
        "def vgg_palface(weights_path=None, **kwargs):\n",
        "    \"\"\"\n",
        "    load imported model instance\n",
        "\n",
        "    Args:\n",
        "        weights_path (str): If set, loads model weights from the given path\n",
        "    \"\"\"\n",
        "    model = VggPal()\n",
        "    if weights_path:\n",
        "        state_dict = torch.load(weights_path)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model"
      ],
      "metadata": {
        "id": "UOSjJUATUOx4"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vggpal = vgg_palface(\"vgg_face_dag.pth\")\n",
        "vggpal.fc8 = nn.Linear(in_features=4096, out_features=7, bias=True)\n",
        "vggpal = vggpal.to(device)"
      ],
      "metadata": {
        "id": "pJKrhFKVVgQM"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Grad(inputs, outputs) :\n",
        "    outputs_sum = outputs.sum()\n",
        "    inputs.retain_grad()\n",
        "    outputs.retain_grad()\n",
        "    outputs_sum.backward(retain_graph=True)\n",
        "    return torch.abs(inputs.grad)\n",
        "\n",
        "def GradxInput(inputs, outputs) :\n",
        "    Grad_val = Grad(inputs, outputs)\n",
        "    return Grad_val * inputs\n",
        "\n",
        "def pal_loss(inputs, outputs, prior, attribution_method, channel_strategy=None) :\n",
        "    attribution_map = attribution_method(inputs, outputs)\n",
        "    \n",
        "    if channel_strategy == \"half_mean\" :\n",
        "        nb_class = attribution_map.shape[1]\n",
        "        attribution_map[:, nb_class/2:, :, :]\n",
        "    \n",
        "    if channel_strategy == \"half_mean\" or channel_strategy == \"mean\" :\n",
        "        attribution_map = attribution_map.mean(1).unsqueeze(1)\n",
        "    \n",
        "    attribution_map_resize = transforms.Resize(attribution_map.shape[-2:])\n",
        "    \n",
        "    prior = attribution_map_resize(prior)\n",
        "    \n",
        "    std = attribution_map.view(attribution_map.size(0), -1).std(1)\n",
        "    mean = attribution_map.view(attribution_map.size(0), -1).mean(1)\n",
        "    \n",
        "    \n",
        "    res = (attribution_map - mean.view(-1, 1, 1, 1)) / std.view(-1, 1, 1, 1)\n",
        "    res = res * prior.unsqueeze(1)\n",
        "    \n",
        "    res = res.view(res.size(0), -1).sum(1)\n",
        "    res = -res\n",
        "    return res.mean()"
      ],
      "metadata": {
        "id": "gjeV_zDwZHx8"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tot_loss(li, lo, prior, logits, y):\n",
        "  p_loss = pal_loss(li,lo,prior,GradxInput,\"half_mean\")\n",
        "  ce_loss = cross_entropy(logits, y)\n",
        "  return pal_loss + ce_loss"
      ],
      "metadata": {
        "id": "puU0EGIdZOjx"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_modelpal(net, loader):\n",
        "  net.eval()\n",
        "  acc, loss = 0., 0.\n",
        "  c = 0\n",
        "  for x, prior, y in loader:\n",
        "    li, lo, logits = net(x.to(device))\n",
        "    li, lo, logits = li.cpu(), lo.cpu(), logits.cpu()\n",
        "    loss += tot_loss(li, lo, prior, logits, y).item()\n",
        "    preds = logits.argmax(dim=1)\n",
        "    acc += (preds.numpy() == y.numpy()).sum()\n",
        "    c += len(x)\n",
        "    break\n",
        "\n",
        "  acc /= c\n",
        "  loss /= len(loader)\n",
        "  net.train()\n",
        "  return acc, loss"
      ],
      "metadata": {
        "id": "FOqWGhSqZBDc"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_acc, initial_loss = eval_modelpal(vggpal, val_loader)\n",
        "print(f\"Initial accuracy/loss on val: {round(100 * initial_acc, 2)}/{round(initial_loss, 4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "UYNlujThVo6i",
        "outputId": "5ceda1aa-248c-4b0b-fd4d-094fe01d9fb2"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-eb432323d954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minitial_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_modelpal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvggpal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Initial accuracy/loss on val: {round(100 * initial_acc, 2)}/{round(initial_loss, 4)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-84-22094000d8e6>\u001b[0m in \u001b[0;36meval_modelpal\u001b[0;34m(net, loader)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mli\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mli\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mli\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-83-d2cebc7033a2>\u001b[0m in \u001b[0;36mtot_loss\u001b[0;34m(li, lo, prior, logits, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mp_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGradxInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"half_mean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mce_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mpal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mce_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-1ee23419b128>\u001b[0m in \u001b[0;36mpal_loss\u001b[0;34m(inputs, outputs, prior, attribution_method, channel_strategy)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattribution_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mattribution_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattribution_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchannel_strategy\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"half_mean\"\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-1ee23419b128>\u001b[0m in \u001b[0;36mGradxInput\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mGradxInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mGrad_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mGrad_val\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-1ee23419b128>\u001b[0m in \u001b[0;36mGrad\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutputs_sum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mGradxInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: abs(): argument 'input' (position 1) must be Tensor, not NoneType"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(vggpal.parameters(), lr=0.00005)\n",
        "scheduler = PolynomialLR(optimizer, total_iters=75, power=1.0)\n",
        "\n",
        "nb_epochs = 75\n",
        "\n",
        "train_accs, train_losses = [], []\n",
        "val_accs, val_losses = [], []"
      ],
      "metadata": {
        "id": "itbzcRpwV9Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "best_acc = 0\n",
        "for epoch in range(nb_epochs):\n",
        "  with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "    start = time.time()\n",
        "    running_acc, running_loss = 0., 0.\n",
        "    c = 0\n",
        "    for x, prior, y in tepoch:\n",
        "      x, prior, y = x.to(device), prior.to(device),y.to(device)\n",
        "\n",
        "      optimizer.zero_grad()  # Clear previous gradients\n",
        "      li, lo ,logits = vggpal(x)\n",
        "      loss = tot_loss(li, lo, prior, logits, y)\n",
        "      loss.backward()  # Compute gradients\n",
        "      optimizer.step()  # Update weights with gradients\n",
        "      scheduler.step()\n",
        "\n",
        "      running_acc += (logits.argmax(dim=1).cpu().numpy() == y.cpu().numpy()).sum()\n",
        "      running_loss += loss.item()\n",
        "      c += len(x)\n",
        "      tepoch.set_postfix(loss=loss.item())\n",
        "\n",
        "    train_acc, train_loss = running_acc / c, running_loss / len(train_loader)\n",
        "    train_accs.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "    \n",
        "    val_acc, val_loss = eval_model(vggpal, val_loader, cross_entropy)\n",
        "    if val_acc > best_acc:\n",
        "      best_acc = val_acc\n",
        "      torch.save(vggpal.state_dict(),\"vggpal_best_param.pth\")\n",
        "    val_accs.append(val_acc)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1}/{nb_epochs}, \"\n",
        "        f\"train acc/loss: {round(100 * train_acc, 2)}/{round(train_loss, 4)}, \"\n",
        "        f\"val acc/loss: {round(100 * val_acc, 2)}/{round(val_loss, 4)}, \"\n",
        "        f\"time {int(time.time() - start)}s\"\n",
        "    )"
      ],
      "metadata": {
        "id": "X5f7XGWyWGZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(list(range(nb_epochs)), train_accs, label=\"Train\")\n",
        "plt.plot(list(range(nb_epochs)), val_accs, label=\"Val\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(list(range(nb_epochs)), train_losses, label=\"Train\")\n",
        "plt.plot(list(range(nb_epochs)), val_losses, label=\"Val\")\n",
        "plt.title(\"Loss\")"
      ],
      "metadata": {
        "id": "c3DdRcYgXx5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load(\"vggpal_best_param.pth\")\n",
        "vgg.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "RdM_4qN_X0T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc, test_loss = eval_model(vgg, test_loader, cross_entropy)\n",
        "test_acc, test_loss"
      ],
      "metadata": {
        "id": "5OwF7dnQX4Lt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}