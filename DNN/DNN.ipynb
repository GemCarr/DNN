{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lmtw_pSbGjCY",
        "outputId": "62879ce8-0b61-48f4-f06b-8feb1d5fa2f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ],
      "source": [
        "%pylab inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5fYVvVnPkzJk"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_I5X_GW80eo",
        "outputId": "0160f382-db53-49e4-c4e3-ccc510a5dc14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "lYs2w5tERN6S"
      },
      "source": [
        "## Download RAF-DB dataset (Google Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0OqFiGiKzIg",
        "outputId": "21e150b9-8efd-4516-c0a3-1db99a2c7c2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-29 14:46:32--  https://github.com/MegaloPat/DNN/raw/main/DNN/aligned.zip\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/MegaloPat/DNN/main/DNN/aligned.zip [following]\n",
            "--2023-01-29 14:46:32--  https://raw.githubusercontent.com/MegaloPat/DNN/main/DNN/aligned.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 39152089 (37M) [application/zip]\n",
            "Saving to: ‘aligned.zip’\n",
            "\n",
            "aligned.zip         100%[===================>]  37.34M  72.8MB/s    in 0.5s    \n",
            "\n",
            "2023-01-29 14:46:34 (72.8 MB/s) - ‘aligned.zip’ saved [39152089/39152089]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://github.com/MegaloPat/DNN/raw/main/DNN/aligned.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRUMP23yRN6W",
        "outputId": "baf2c171-121b-42bd-8c8a-25dfe8170438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-29 14:46:35--  https://github.com/MegaloPat/DNN/raw/main/DNN/landmark.zip\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/MegaloPat/DNN/main/DNN/landmark.zip [following]\n",
            "--2023-01-29 14:46:35--  https://raw.githubusercontent.com/MegaloPat/DNN/main/DNN/landmark.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 86475976 (82M) [application/zip]\n",
            "Saving to: ‘landmark.zip’\n",
            "\n",
            "landmark.zip        100%[===================>]  82.47M   141MB/s    in 0.6s    \n",
            "\n",
            "2023-01-29 14:46:39 (141 MB/s) - ‘landmark.zip’ saved [86475976/86475976]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://github.com/MegaloPat/DNN/raw/main/DNN/landmark.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suemGu3wRN6Y",
        "outputId": "19391002-788c-431f-c9c4-e2c55f7b2982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-29 14:46:39--  https://raw.githubusercontent.com/MegaloPat/DNN/main/DNN/list_patition_label.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 285305 (279K) [text/plain]\n",
            "Saving to: ‘list_patition_label.txt’\n",
            "\n",
            "\rlist_patition_label   0%[                    ]       0  --.-KB/s               \rlist_patition_label 100%[===================>] 278.62K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-01-29 14:46:40 (18.2 MB/s) - ‘list_patition_label.txt’ saved [285305/285305]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://raw.githubusercontent.com/MegaloPat/DNN/main/DNN/list_patition_label.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u6BzVPDRN6a"
      },
      "source": [
        "## Download pretrained VGG_Face weights (Google Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xaaP6dBLZM8",
        "outputId": "aa37fb5d-6541-4133-b1f8-12390b68ada4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-29 14:46:40--  https://www.robots.ox.ac.uk/~albanie/models/pytorch-mcn/vgg_face_dag.pth\n",
            "Resolving www.robots.ox.ac.uk (www.robots.ox.ac.uk)... 129.67.94.2\n",
            "Connecting to www.robots.ox.ac.uk (www.robots.ox.ac.uk)|129.67.94.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 580015466 (553M)\n",
            "Saving to: ‘vgg_face_dag.pth’\n",
            "\n",
            "vgg_face_dag.pth    100%[===================>] 553.15M  89.3MB/s    in 5.8s    \n",
            "\n",
            "2023-01-29 14:46:46 (95.4 MB/s) - ‘vgg_face_dag.pth’ saved [580015466/580015466]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "! wget https://www.robots.ox.ac.uk/~albanie/models/pytorch-mcn/vgg_face_dag.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK-qn9hFeHqA"
      },
      "source": [
        "# I - Vanilla classification with pretrained VGG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPuFjHO5RN6e"
      },
      "source": [
        "First we will try to get baseline results with VGG pretrained on VGG_Face without any changes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFWWOXXueWol"
      },
      "source": [
        "## Prepare dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAljxGKMeQ0g"
      },
      "source": [
        "### Unzip data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5V-l3Mf6TTQq"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"aligned.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./aligned\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "j3hUoGmxTTQr"
      },
      "outputs": [],
      "source": [
        "!mkdir aligned/train\n",
        "!mkdir aligned/test\n",
        "!mv aligned/aligned/train_* aligned/train\n",
        "!mv aligned/aligned/test_* aligned/test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9KfQpHqebCw"
      },
      "source": [
        "### Prepare csv labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_gf_GRWUTTQs"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "with open(\"list_patition_label.txt\",\"r\") as file :\n",
        "    train_csv = open(\"train_list_label.csv\",\"w\",newline=\"\")\n",
        "    test_csv = open(\"test_list_label.csv\",\"w\",newline=\"\")\n",
        "\n",
        "    train_writer = csv.writer(train_csv)\n",
        "    train_writer.writerow([\"Filename\", \"Label\"])\n",
        "    \n",
        "    test_writer = csv.writer(test_csv)\n",
        "    test_writer.writerow([\"Filename\", \"Label\"])\n",
        "    \n",
        "    \n",
        "    for line in file:\n",
        "        filename, label = line.strip().split(\" \")\n",
        "        idx = filename.index(\".jpg\")\n",
        "        filename = filename[:idx] + \"_aligned\" + filename[idx:]\n",
        "        label = str(int(label) - 1)\n",
        "        \n",
        "        if \"train\" in filename :\n",
        "            train_writer.writerow([filename, label])\n",
        "        else :\n",
        "            test_writer.writerow([filename, label])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTAvN8J3egfk"
      },
      "source": [
        "### Preprocessing transform\n",
        "Preprocessing is the same as the experimental protocol of the original paper. This includes :\n",
        "* Resize to 224x224\n",
        "* Random rotation of -10° +10°\n",
        "* Random horizontal flip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9MF1-iFsTTQt"
      },
      "outputs": [],
      "source": [
        "trans = transforms.Compose([\n",
        "    transforms.Lambda(lambda x: x.float()),\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomHorizontalFlip()\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaC7JedKenG_"
      },
      "source": [
        "### Create dataloaders\n",
        "Validation set will be sampled with a stratified split of test set, as in the paper, with ratio 50/50.\n",
        "\n",
        "Overall the proportions for the train/test/validation datasets are 80/10/10 %\n",
        "\n",
        "Finally, we will use a batch size of 16 as in the paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RhF0_COyTTQv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFB9WkgxTTQx",
        "outputId": "2bc3cc4d-98c9-431b-d8c6-994508493db3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nb batches in train: 758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "train_data = CustomImageDataset(\"train_list_label.csv\",\"./aligned/train\", transform=trans)\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=4)\n",
        "print(f\"\\nNb batches in train: {len(train_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "I2paf1E6TTQy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "test_data = CustomImageDataset(\"test_list_label.csv\",\"./aligned/test\", transform=trans)\n",
        "\n",
        "test_indices, val_indices = train_test_split(list(range(len(test_data.img_labels.Label))), test_size=0.5, stratify=test_data.img_labels.Label)\n",
        "\n",
        "val_data = torch.utils.data.Subset(test_data, val_indices)\n",
        "test_data = torch.utils.data.Subset(test_data, test_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0vmJvM_c96n",
        "outputId": "ebf680a6-9a3d-4fbc-a260-0492c355f332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nb batches in test: 92\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "test_loader = DataLoader(test_data, batch_size=16, shuffle=True, num_workers=4)\n",
        "print(f\"\\nNb batches in test: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Cztj6-wc_iE",
        "outputId": "3f5f4dc6-452d-4d6f-86ad-f24c74ea6b13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nb batches in val: 92\n"
          ]
        }
      ],
      "source": [
        "val_loader = DataLoader(val_data, batch_size=16, shuffle=True, num_workers=4)\n",
        "print(f\"\\nNb batches in val: {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpPiJoR9ewyx"
      },
      "source": [
        "## VGG class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RF0r5z--TTQ0"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Vgg(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Vgg, self).__init__()\n",
        "        self.meta = {'mean': [129.186279296875, 104.76238250732422, 93.59396362304688],\n",
        "                     'std': [1, 1, 1],\n",
        "                     'imageSize': [224, 224, 3]}\n",
        "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu1_1 = nn.ReLU(inplace=True)\n",
        "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu1_2 = nn.ReLU(inplace=True)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu2_1 = nn.ReLU(inplace=True)\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu2_2 = nn.ReLU(inplace=True)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
        "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu3_1 = nn.ReLU(inplace=True)\n",
        "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu3_2 = nn.ReLU(inplace=True)\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu3_3 = nn.ReLU(inplace=True)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
        "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu4_1 = nn.ReLU(inplace=True)\n",
        "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu4_2 = nn.ReLU(inplace=True)\n",
        "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu4_3 = nn.ReLU(inplace=True)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
        "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu5_1 = nn.ReLU(inplace=True)\n",
        "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu5_2 = nn.ReLU(inplace=True)\n",
        "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1))\n",
        "        self.relu5_3 = nn.ReLU(inplace=True)\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=[2, 2], stride=[2, 2], padding=0, dilation=1, ceil_mode=False)\n",
        "        self.fc6 = nn.Linear(in_features=25088, out_features=4096, bias=True)\n",
        "        self.relu6 = nn.ReLU(inplace=True)\n",
        "        self.dropout6 = nn.Dropout(p=0.5)\n",
        "        self.fc7 = nn.Linear(in_features=4096, out_features=4096, bias=True)\n",
        "        self.relu7 = nn.ReLU(inplace=True)\n",
        "        self.dropout7 = nn.Dropout(p=0.5)\n",
        "        self.fc8 = nn.Linear(in_features=4096, out_features=7, bias=True)\n",
        "\n",
        "\n",
        "    def forward(self, x0):\n",
        "        x1 = self.conv1_1(x0)\n",
        "        x2 = self.relu1_1(x1)\n",
        "        x3 = self.conv1_2(x2)\n",
        "        x4 = self.relu1_2(x3)\n",
        "        x5 = self.pool1(x4)\n",
        "        x6 = self.conv2_1(x5)\n",
        "        x7 = self.relu2_1(x6)\n",
        "        x8 = self.conv2_2(x7)\n",
        "        x9 = self.relu2_2(x8)\n",
        "        x10 = self.pool2(x9)\n",
        "        x11 = self.conv3_1(x10)\n",
        "        x12 = self.relu3_1(x11)\n",
        "        x13 = self.conv3_2(x12)\n",
        "        x14 = self.relu3_2(x13)\n",
        "        x15 = self.conv3_3(x14)\n",
        "        x16 = self.relu3_3(x15)\n",
        "        x17 = self.pool3(x16)\n",
        "        x18 = self.conv4_1(x17)\n",
        "        x19 = self.relu4_1(x18)\n",
        "        x20 = self.conv4_2(x19)\n",
        "        x21 = self.relu4_2(x20)\n",
        "        x22 = self.conv4_3(x21)\n",
        "        x23 = self.relu4_3(x22)\n",
        "        x24 = self.pool4(x23)\n",
        "        x25 = self.conv5_1(x24)\n",
        "        x26 = self.relu5_1(x25)\n",
        "        x27 = self.conv5_2(x26)\n",
        "        x28 = self.relu5_2(x27)\n",
        "        x29 = self.conv5_3(x28)\n",
        "        x30 = self.relu5_3(x29)\n",
        "        x31_preflatten = self.pool5(x30)\n",
        "        x31 = x31_preflatten.view(x31_preflatten.size(0), -1)\n",
        "        x32 = self.fc6(x31)\n",
        "        x33 = self.relu6(x32)\n",
        "        x34 = self.dropout6(x33)\n",
        "        x35 = self.fc7(x34)\n",
        "        x36 = self.relu7(x35)\n",
        "        x37 = self.dropout7(x36)\n",
        "        x38 = self.fc8(x37)\n",
        "        return x38\n",
        "\n",
        "def vgg_face(weights_path=None, **kwargs):\n",
        "    \"\"\"\n",
        "    load imported model instance\n",
        "\n",
        "    Args:\n",
        "        weights_path (str): If set, loads model weights from the given path\n",
        "    \"\"\"\n",
        "    model = Vgg()\n",
        "    if weights_path:\n",
        "        state_dict = torch.load(weights_path)\n",
        "        state_dict.pop(\"fc6.weight\")\n",
        "        state_dict.pop(\"fc6.bias\")\n",
        "        state_dict.pop(\"fc7.weight\")\n",
        "        state_dict.pop(\"fc7.bias\")\n",
        "        state_dict.pop(\"fc8.weight\")\n",
        "        state_dict.pop(\"fc8.bias\")\n",
        "        model.load_state_dict(state_dict, strict=False)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6znD8m3e0UX"
      },
      "source": [
        "### Load pretrained weights on vgg_face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-mz1UwaITTQ1"
      },
      "outputs": [],
      "source": [
        "vgg = vgg_face(\"vgg_face_dag.pth\")\n",
        "vgg = vgg.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfE_h1R5e44U"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2Vz0Yf4e7kU"
      },
      "source": [
        "### Initial evaluation on validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qyUWv3xVg6j8"
      },
      "outputs": [],
      "source": [
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "def eval_model(net, loader):\n",
        "  net.eval()\n",
        "  acc, loss = 0., 0.\n",
        "  c = 0\n",
        "  for x, y in loader:\n",
        "    with torch.no_grad():\n",
        "      # No need to compute gradient here thus we avoid storing intermediary activations\n",
        "      logits = net(x.to(device)).cpu()\n",
        "\n",
        "    loss += cross_entropy(logits, y).item()\n",
        "    preds = logits.argmax(dim=1)\n",
        "    acc += (preds.numpy() == y.numpy()).sum()\n",
        "    c += len(x)\n",
        "\n",
        "  acc /= c\n",
        "  loss /= len(loader)\n",
        "  net.train()\n",
        "  return acc, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzWqyNeOTTQ2",
        "outputId": "777996bf-9e8a-43f1-8b0e-af0e33ace55e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial accuracy/loss on val: 9.17/2.7371\n"
          ]
        }
      ],
      "source": [
        "initial_acc, initial_loss = eval_model(vgg, val_loader)\n",
        "print(f\"Initial accuracy/loss on val: {round(100 * initial_acc, 2)}/{round(initial_loss, 4)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEUMsdH-fF79"
      },
      "source": [
        "### Training\n",
        "\n",
        "Training will be performed with adam optimizer, using a base learning rate of 5e-5 and polynomial decay on all epochs with a power of 0.5, for 75 epochs.  \n",
        "We will save the best model according to the accuracy on the validation set.  \n",
        "These parameters follow the experimental protocol of the paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HFqWHdsKfC_O"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import PolynomialLR\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(vgg.parameters(), lr=0.00005)\n",
        "scheduler = PolynomialLR(optimizer, total_iters=75, power=2)\n",
        "\n",
        "nb_epochs = 75\n",
        "\n",
        "train_accs, train_losses = [], []\n",
        "val_accs, val_losses = [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27MCDp2JTTQ2",
        "outputId": "0e50a490-94b8-4723-a493-19e602720818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:42<00:00,  3.40batch/s, loss=0.705]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75, train acc/loss: 64.09/1.0287, val acc/loss: 76.63/0.725, time 233s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:41<00:00,  3.43batch/s, loss=0.268]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/75, train acc/loss: 77.72/0.656, val acc/loss: 81.11/0.5792, time 231s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:41<00:00,  3.43batch/s, loss=0.0805]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/75, train acc/loss: 82.55/0.5245, val acc/loss: 80.1/0.5996, time 229s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.43batch/s, loss=0.455]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/75, train acc/loss: 85.63/0.4317, val acc/loss: 80.43/0.578, time 229s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.43batch/s, loss=0.528]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/75, train acc/loss: 87.9/0.3652, val acc/loss: 82.0/0.5502, time 231s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.44batch/s, loss=0.115]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/75, train acc/loss: 89.61/0.3015, val acc/loss: 84.38/0.5419, time 230s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.44batch/s, loss=0.033]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/75, train acc/loss: 91.42/0.2534, val acc/loss: 82.74/0.7013, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.278]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/75, train acc/loss: 93.19/0.2085, val acc/loss: 83.9/0.5869, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.45batch/s, loss=0.293]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/75, train acc/loss: 93.84/0.1837, val acc/loss: 83.49/0.6098, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.44batch/s, loss=0.166]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/75, train acc/loss: 95.12/0.1491, val acc/loss: 83.29/0.6642, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.023]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/75, train acc/loss: 95.56/0.138, val acc/loss: 84.17/0.578, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.0125]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/75, train acc/loss: 96.5/0.1115, val acc/loss: 84.92/0.6096, time 230s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.0981]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/75, train acc/loss: 96.72/0.0981, val acc/loss: 83.56/0.7355, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.44batch/s, loss=0.0004]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/75, train acc/loss: 96.94/0.096, val acc/loss: 84.04/0.7467, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.122]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/75, train acc/loss: 97.1/0.0831, val acc/loss: 84.17/0.7017, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.216]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/75, train acc/loss: 97.59/0.0712, val acc/loss: 83.9/0.7717, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.00282]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/75, train acc/loss: 98.06/0.0606, val acc/loss: 83.49/0.9617, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.00188]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/75, train acc/loss: 97.76/0.0655, val acc/loss: 84.1/0.7226, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.535]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/75, train acc/loss: 98.05/0.0565, val acc/loss: 84.71/0.7631, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.277]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/75, train acc/loss: 98.39/0.047, val acc/loss: 84.85/0.7385, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.0231]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/75, train acc/loss: 98.38/0.0504, val acc/loss: 83.76/0.8841, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=5.78e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/75, train acc/loss: 98.85/0.0375, val acc/loss: 84.38/0.9789, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.0204]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/75, train acc/loss: 98.89/0.0354, val acc/loss: 83.7/0.9775, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.00355]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/75, train acc/loss: 98.89/0.0367, val acc/loss: 83.02/0.9421, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.00327]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/75, train acc/loss: 98.84/0.0352, val acc/loss: 85.19/0.8589, time 230s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.000695]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/75, train acc/loss: 99.03/0.0314, val acc/loss: 84.71/0.8724, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.00117]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/75, train acc/loss: 99.17/0.026, val acc/loss: 85.19/0.9102, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.000238]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/75, train acc/loss: 99.22/0.0249, val acc/loss: 84.65/0.9603, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.147]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/75, train acc/loss: 99.17/0.0252, val acc/loss: 85.53/0.8378, time 230s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.00015]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/75, train acc/loss: 99.42/0.0167, val acc/loss: 85.6/1.2101, time 230s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.00329]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/75, train acc/loss: 99.24/0.0251, val acc/loss: 85.53/0.9538, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.44batch/s, loss=0.0695]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/75, train acc/loss: 99.55/0.018, val acc/loss: 86.35/0.9351, time 231s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=5.11e-8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/75, train acc/loss: 99.47/0.0161, val acc/loss: 85.6/1.0324, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.44batch/s, loss=0.000174]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/75, train acc/loss: 99.6/0.0129, val acc/loss: 85.05/1.3262, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.000133]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/75, train acc/loss: 99.5/0.0181, val acc/loss: 84.65/0.9949, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.45batch/s, loss=4.77e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/75, train acc/loss: 99.51/0.0131, val acc/loss: 84.85/1.2436, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=8.85e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/75, train acc/loss: 99.63/0.0106, val acc/loss: 83.7/1.1518, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=3.24e-7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/75, train acc/loss: 99.74/0.0087, val acc/loss: 85.05/1.2651, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=4.68e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/75, train acc/loss: 99.73/0.0114, val acc/loss: 84.99/1.1603, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=1.12e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/75, train acc/loss: 99.73/0.0077, val acc/loss: 84.24/1.4317, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/75, train acc/loss: 99.88/0.0034, val acc/loss: 85.73/1.4012, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=1.88e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/75, train acc/loss: 99.71/0.0092, val acc/loss: 84.78/1.3046, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=1.28e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/75, train acc/loss: 99.82/0.0058, val acc/loss: 86.28/1.3636, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/75, train acc/loss: 99.89/0.0042, val acc/loss: 85.94/1.2653, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=2.04e-7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/75, train acc/loss: 99.85/0.0053, val acc/loss: 86.14/1.2679, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.44batch/s, loss=3.58e-7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/75, train acc/loss: 99.93/0.002, val acc/loss: 85.12/1.4346, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.44batch/s, loss=0.000147]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/75, train acc/loss: 99.86/0.0037, val acc/loss: 86.28/1.3983, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=1.53e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/75, train acc/loss: 99.88/0.0038, val acc/loss: 84.71/1.1672, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=7.65e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/75, train acc/loss: 99.91/0.0034, val acc/loss: 85.46/1.4465, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/75, train acc/loss: 99.92/0.0031, val acc/loss: 86.28/1.2651, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=3.41e-8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51/75, train acc/loss: 99.92/0.0023, val acc/loss: 85.53/1.4017, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52/75, train acc/loss: 99.98/0.002, val acc/loss: 85.19/1.3144, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=5.11e-8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53/75, train acc/loss: 99.99/0.0003, val acc/loss: 87.02/1.3367, time 230s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=2.38e-7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54/75, train acc/loss: 99.94/0.0024, val acc/loss: 86.35/1.4411, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.44batch/s, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55/75, train acc/loss: 99.99/0.0004, val acc/loss: 85.94/1.4771, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56/75, train acc/loss: 99.99/0.0006, val acc/loss: 86.41/1.4861, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57/75, train acc/loss: 99.98/0.0015, val acc/loss: 86.28/1.4328, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.44batch/s, loss=9.48e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58/75, train acc/loss: 100.0/0.0002, val acc/loss: 86.41/1.4642, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=5.64e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59/75, train acc/loss: 99.98/0.0004, val acc/loss: 86.62/1.411, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.44batch/s, loss=1.7e-8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60/75, train acc/loss: 100.0/0.0001, val acc/loss: 86.01/1.5445, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=2.55e-7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61/75, train acc/loss: 100.0/0.0001, val acc/loss: 85.8/1.5086, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0.00112]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62/75, train acc/loss: 99.99/0.0003, val acc/loss: 85.6/1.6099, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.46batch/s, loss=3.41e-8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63/75, train acc/loss: 100.0/0.0002, val acc/loss: 86.82/1.5996, time 227s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.43batch/s, loss=3.41e-8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64/75, train acc/loss: 100.0/0.0001, val acc/loss: 86.68/1.5429, time 229s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:41<00:00,  3.42batch/s, loss=0.000274]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65/75, train acc/loss: 99.99/0.0003, val acc/loss: 87.43/1.4893, time 232s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.44batch/s, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66/75, train acc/loss: 100.0/0.0001, val acc/loss: 86.35/1.6264, time 229s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:40<00:00,  3.44batch/s, loss=3.27e-5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67/75, train acc/loss: 100.0/0.0, val acc/loss: 85.8/1.6941, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68/75, train acc/loss: 100.0/0.0001, val acc/loss: 86.41/1.6295, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69/75, train acc/loss: 100.0/0.0, val acc/loss: 86.62/1.5891, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=1.02e-7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70/75, train acc/loss: 99.99/0.0002, val acc/loss: 86.41/1.6142, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71/75, train acc/loss: 100.0/0.0, val acc/loss: 85.94/1.7246, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72/75, train acc/loss: 100.0/0.0, val acc/loss: 87.23/1.5663, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73/75, train acc/loss: 99.99/0.0002, val acc/loss: 86.01/1.6288, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=1.07e-6]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74/75, train acc/loss: 100.0/0.0, val acc/loss: 86.89/1.5909, time 228s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 758/758 [03:39<00:00,  3.45batch/s, loss=1.7e-8]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75/75, train acc/loss: 99.99/0.0007, val acc/loss: 86.28/1.609, time 228s\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "best_acc = 0\n",
        "for epoch in range(nb_epochs):\n",
        "  with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "    start = time.time()\n",
        "    running_acc, running_loss = 0., 0.\n",
        "    c = 0\n",
        "    for x, y in tepoch:\n",
        "      x, y = x.to(device), y.to(device)\n",
        "\n",
        "      optimizer.zero_grad()  # Clear previous gradients\n",
        "      logits = vgg(x)\n",
        "      loss = cross_entropy(logits, y)\n",
        "      loss.backward()  # Compute gradients\n",
        "      optimizer.step()  # Update weights with gradients\n",
        "\n",
        "      running_acc += (logits.argmax(dim=1).cpu().numpy() == y.cpu().numpy()).sum()\n",
        "      running_loss += loss.item()\n",
        "      c += len(x)\n",
        "      tepoch.set_postfix(loss=loss.item())\n",
        "    \n",
        "    scheduler.step()\n",
        "    train_acc, train_loss = running_acc / c, running_loss / len(train_loader)\n",
        "    train_accs.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "    \n",
        "    val_acc, val_loss = eval_model(vgg, val_loader)\n",
        "    if val_acc > best_acc:\n",
        "      best_acc = val_acc\n",
        "      torch.save(vgg.state_dict(),\"vgg_best_param.pth\")\n",
        "    val_accs.append(val_acc)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1}/{nb_epochs}, \"\n",
        "        f\"train acc/loss: {round(100 * train_acc, 2)}/{round(train_loss, 4)}, \"\n",
        "        f\"val acc/loss: {round(100 * val_acc, 2)}/{round(val_loss, 4)}, \"\n",
        "        f\"time {int(time.time() - start)}s\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "INtYIpmcosHw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "cc8218f3-5e04-45e5-fa05-fbdf9edd3a03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3hcxdX/P0erXi1ZsuUmd9wbCJtiQgdTTQmJIRBISBxCSIFUEgIE3iSE5PeGN4EkEGIIKRhCgDhgAoRejBu4V7lLtqxmFatrd35/nHu9K1llJa3KrubzPPvc3Zm5d0f27nfPPXPmHDHGYLFYLJbIJaqvJ2CxWCyWnsUKvcVisUQ4VugtFoslwrFCb7FYLBGOFXqLxWKJcKzQWywWS4Rjhd5isVgiHCv0PYyIvC0iR0Qkrq/nYrH0JSKyV0TO6+t5DESs0PcgIjIGOAMwwOW9+L7RvfVeFoul/2OFvmf5PPAR8CRwo9soIqNE5HkRKRaRUhF5OKDvyyKyVUSqRGSLiJzotBsRmRAw7kkR+R/n+Vkiki8i3xeRQuAJEUkXkZec9zjiPB8ZcH6GiDwhIged/hed9k0iclnAuBgRKRGROT32r2QZsIhInIg85HwODzrP45y+TOdzWy4iZSLynohEOX3fF5EC53uyXUTO7du/pH9jhb5n+TzwN+dxoYgMFREP8BKwDxgDjACWAojINcC9znmp6F1AaZDvlQ1kAKOBxej/7RPO6xygFng4YPxfgERgGjAE+LXT/hRwfcC4i4FDxphPgpyHxdIZfgScAswGZgFzgbucvm8D+UAWMBT4IWBEZBJwG3CyMSYFuBDY27vTDi/sLX4PISLzUZF91hhTIiK7gOtQC3848F1jTJMz/H3n+CXgQWPMaud1Xife0gfcY4ypd17XAv8MmM9Pgbec58OAi4DBxpgjzpB3nONfgR+LSKoxphK4Af1RsFh6gs8BXzfGFAGIyE+AR4EfA43AMGC0MSYPeM8Z4wXigKkiUmyM2dsXEw8nrEXfc9wIvGaMKXFe/91pGwXsCxD5QEYBu7r4fsXGmDr3hYgkisijIrJPRCqBd4FBzh3FKKAsQOSPYYw5CHwAXC0ig9AfhL91cU4WS0cMR+9uXfY5bQC/RI2d10Rkt4j8AMAR/W+hd79FIrJURIZjaRMr9D2AiCQAnwHOFJFCx29+O3prehjIaWPB9AAwvo3L1qCuFpfsFv0t05B+G5gEzDPGpAKfcqfnvE+GI+St8WfUfXMNsMIYU9DGOIuluxxE73xdcpw2jDFVxphvG2PGoW7MO1xfvDHm78YY967ZAL/o3WmHF1boe4YrAC8wFfU9zgamoLeeVwCHgAdEJElE4kXkdOe8x4HviMhJokwQEfdLsA64TkQ8IrIAOLODOaSg7ptyEckA7nE7jDGHgFeA3zmLtjEi8qmAc18ETgS+ifrsLZZQEeN85uNFJB54GrhLRLJEJBO4G3UfIiKXOt8BASrQ75RPRCaJyDnOom0d+jn39c2fEx5Yoe8ZbgSeMMbsN8YUug90MfRa4DJgArAfXWz6LIAx5h/AT1E3TxUquBnONb/pnFeO+jVf7GAODwEJQAm6LvCfFv03oD7QbUAReiuMMw/Xvz8WeL6Tf7vF0h7LUWF2H/HAGmADsBH4GPgfZ+xE4L/AUWAF8DtjzFuof/4B9LNdiAYT3Nl7f0L4IbbwiKU1RORu4ARjzPUdDrZYLP0aG3VjOQ7H1XMzavVbLJYwx7puLM0QkS+ji7WvGGPe7ev5WCyW7mNdNxaLxRLhWIveYrFYIpx+56PPzMw0Y8aM6etpWCKYtWvXlhhjsnr7fe1n29KTtPe57ndCP2bMGNasWdPX07BEMCKyr+NRocd+ti09SXufa+u6sVgslgjHCr3FYrFEOP3OdWOx9BYisgS4FCgyxkxvpf+76C5k0O/KFCDLGFMmInvR3cteoMkYk9s7s7ZYOo+16C0DmSeBBW11GmN+aYyZbYyZjW6xf8cYUxYw5Gyn34q8pV9jhd4yYHE2hJV1OFC5Fk3AZbGEHR0KvYgsEZEiEdnURr+IyG9EJE9ENril75y+G0Vkp/O4sbXzLZb+jogkopb/PwOaDZonfa2ILG7n3MUiskZE1hQXF/f0VC2WVgnGon+Sdm5v0cIUE53HYuD3cCxfyj3APLQ82D0ikt6dyVosfcRlwAct3DbzjTEnop//r7VI83wMY8xjxphcY0xuVlavh+5bLEAQi7HGmHdFZEw7QxYCTxnNpfCRiAxyStWdBbzufjlE5HX0B8Pe/vYDjDFU1TeREheNpvv2tzf5DI1eHz4DPmM4WF7LzsNHKa9poL7JR3ZaPENT4zlYXkthRR0G8IiQGOfBGKiobcQYQ0JsNF6fj+p6L26qjWhPFNEeobHJ4PVpCnERITZabY6GJh9tpeWI8UQRFSU0eds+N0qEmGjhlHGDOTEnZHbFIlp8bt1iLMaYIhF5ATVmbG4gS/fIewMGjYbMCSG9bCiibkagSbBc8p22ttqPw7n1XQyQk5MTgikNHCpqGomKgoQYD1EibDlUyR/f201ZdQNfOmMcE4ck89+th1m5p4yN+RXERkeRlRxHXvFRiqvqyUiKZWxmEkfrmiivbeBITSMNTaGv4SACrel3a+0BvzvHCPZclx9cNDkkQi8iaWiRl+sD2pKAKGNMlfP8AuC+br+ZZWBjDPzjCzD5YrjyDyG9dL8IrzTGPAY8BpCbm2uzrAVwoKyG6oYmJg1NOWZ5Hyyv5eUNh3hpw0HW51ccd05yXDQp8dHcuGTVsbYRgxKYNSoNr89wuLKe+RMymTAkmf2lNewrqyZncCKzEtNIT4wlOS6amOgoPM77DU2LZ+KQZDKT44j1RHGwopbCyjpGDEpg+KAEPCI0+nzUNngBSEuIIUqEmoYmoj1RJMZ4iIrSazV5fTT5DDGeKDxOmzGGRq/BYIj1RDW7w3AxxuD1mVbPbfD6EIQYj+Az0Oj1tfpj0RIReRq988wUkXzU1RjjXNf9pl2J1v6tDjh1KPCCM89o4O/GmJaFXSyWzlFdDPUVUBn6yp2hEPoCtNi0y0inrQD9EgW2vx2C94sofD7Dqr1lzByZRkKMh1++up2/fLSPiUOSERHW7tP63UNT4xiVnkhFbSM7i44CMGNEGt+54ATioj3UOCKbnhTDwtkjiI+J4sVPCiivaeS8qUMZn5UcsjmnJcYwZVhqs7YEPKTGxzRri42OPe5cdd00b1P3S/vKLCJEe6TVc+MCGj0CnqgWg9rAGHNtEGOeRNepAtt2o/V/LZbQUZqnx6rCkF86FEK/DLhNRJaiC68VxphDIvIq8LOABdgLsOW+aGjykX+khoRYD3HRHr77j/W8sa2IrJQ4pg1P5e3txZw9KYuquiZqGrx898JJZCXH8c6OYsprGxidmMQVc0ZwyYxhjMlMave9PnuydYNZLP2K3e/Ai7fCV96FpMHN+1yhrzwU8rftUOiDuL1dDlwM5AE1wBecvjIRuR9Y7VzqvhZRCwOGo/VN/GtdAc+uyWdTQQVen987FeMRvnnuRD7cVcLb24u54/wT+Po5E45zX3zm5FEtL2uxWMKNrcugMh/2vA3Tr27e5wp9QxXUV0FcSsjeNpiom3Zvb51om6+10bcEWNK1qYUX+0tr2FZYyeGqenyOHzknI5E9pdU89PoOSqsbmJydwi1njmNsZjK1jV4Oltdy8fRhzBiZxrfOm0jx0XqGpMT39Z9isVh6in0r9LjnvVaEfpf/edXh3hV6S8e8v7OEzy9Zia+NZeS5YzN4bMEkTsxJb3WhEdTXbEXeYolgasqgaLM+3/v+8f2leRCfBnUVUHUwpCGWVui7SenRem5/dh3jspL5f9fMYlhaPNGeKOoavewrrUEE5o3NaFPgLRbLAGH/R3qcdAlsf1l98anDtM3nhbI9MOFc2L485AuyVui7gDGGx9/bw5ZDlewsqqKitpGnvjj3uEiU4YMS+miGFoul37HvA/DEwunfVKHf+z7MvEb7KvLBWw9j5qvQVx4M6Vtboe8kxhjuXbaZP6/Yx/C0eKKihJ9eMf04kbdYLJZm7F8BI3JhZK66aPa+6xd6dyF22GyITbYWfW/z+pbDPL1qP/dfMZ2hKXH8+F+beXrVfhZ/ahx3XjTZumQsFkvH1B+Fg+tg/u0Q5YHRp+uCrIu7EDt4PKQMg6pD4PPBmj/BjGsgYVC33t4KfTscKKvhjmfWUVXfxKZHPmDCkGQ+3FXKrWeN57sXTrIib7FYguPQOjBeyDlFX7u++IOfwPA5atHHJkPyUEjJVqHf+x4s/47ulD3v3m69vc1H3waNXh/fWPoJCCy5KZfoKGHVnjIeuGoG31tgLXmLxdKC8gNQtK2Nvv16zBinxxnXQEwirHlCXx/epNa8iN+i3/OO9q19Ehpr9bG9a5k2rEXfBo+8lccn+8v57bVzOGfyUF7+Rjql1Q1MGBK6VAIWiyWCWHab7nyd+2U49+7mcfAV+XpMdfI6xqfB9Ktg43Pqxtn3AZzzY2fMMPXR734HEjKgtgzWL4W8/+pdwK0rIeuETk3NWvStsCG/nN++mceVc0Zw2azhAKQnxVqRt1gsbVO4Sa3xVX+E5d9t3le+X90yMQF7ZXK/CI3V8OItMHS6RuOAXsPbAAVrdMzQGXq9bS/BhT/vtMiDFfrj2F9aw+3PrCMrOY57L5/W19OxWCzhQE0Z1JTAqbfC7M+p5e1t8vdX5EPayObnDD8RsmcCAgsfBo+TFDAl2z9m3JlwylfB16gLuafc0qXpWdeNw+HKOn62fCv/Xn+Q6Kgoltx0MmkJMR2faLFYLMXb9Zg1GdJGwbq/Qv5qGH2qtlccUKs9EHEEvqJAF2RdUtSLQHQ8jJwLY86AYbNgaNcNzwEv9MYY/rEmn/tf3kJDk48vnzGOL5w+luw0m47AYrEESbGzCJt5goZCigd2vqZCb4xa9Ce0UpF12Cx9BOJa9Dmn+F092S1+JDrJgBb6vSXV/OD5DXy0u4y5YzP4xdUzGdtB6l+LxWI5jpIdGkWTNgqiolSk816H8+6B6hJoqoNBQaYNTxmmi7CTLw3Z9Aas0Btj+MKTqyk5Ws/PrpzBopNHHauCZLFYLJ2ieDsMnqAiDzDxfPjvvZrKwN3l2tJH3xbRsXDHFnXdhIgBuxj78f4j7Cmp5p7LpnHdvBwr8haLpXPsfgf+ejU01qlFnzXZ3zfhfD3ufN0fWhms0APEJLRePLmLDFihf/7jAuJjolgwPbvjwRaLxdKSna9pbPuaJbrYGhj2OHQapI7UMRUHtC2t74oHDUihb2jy8dKGQ1wwNZvkuAHrvbJYLN3BFfC3fqbHzEn+PhGYtAB2vQklOyEmCRLSj79GLzEghf7t7UVU1DZy5Ykj+noqlj5ERJaISJGIbGqj/ywRqRCRdc7j7oC+BSKyXUTyROQHvTdrS7+hfD9EJ2jpP4CsSc37J10EjTWw+XkYNCqkrpjOMuCE3uszPP7+HjKTYzljQmZfT8fStzwJtBLz1oz3jDGzncd9ACLiAR4BLgKmAteKyNQenaml/1F+QMsBpo2CqGh/HhuXMWdoorK6is7553uAoIS+I+tFREaLyBsiskFE3haRkQF93gCLaFkoJ98V/u+/O1i1p4zvXTiZaM+A+52zBGCMeRfoSsH6uUCeMWa3MaYBWAosDOnkLP2bhhrdCZsxBi56EM74tn9nq0t0HIw/R5/3oX8eghD6IK2XXwFPGWNmAvcBPw/oqw2wiC4P0by7xAd5Jfz2rTyuOWkknzm5b//hLWHDqSKyXkReERF3a+II4EDAmHyn7ThEZLGIrBGRNcXFxT09V0uoqasAb+Px7cciaXJg8sVw9g9bP3/Sxc64/m/RB2O9TAXedJ6/1Up/v+CpFXsZmhLPfQu7t8vMMmD4GBhtjJkF/BZ4sbMXMMY8ZozJNcbkZmVlhXyClh6ipgz+80N4cDy8+T/H97tphwd1YDCecKGmPhgzP/Rz7ATBCH0w1st64Crn+ZVAiogMdl7HOxbNRyJyRWtv0BtWj9dn+HBXKWdPziIh1tMj72GJLIwxlcaYo87z5UCMiGQCBUDgN3yk02aJBHw+eOpyWPl7jZTZ9LymMQikwhX6Dna7JmbAVz/wFxzpI0LlpP4OcKaIfAKciX7ovU7faGNMLnAd8JCIjG95cm9YPRsLKqiqa+J0uwBrCRIRyRanwoyIzEW/L6XAamCiiIwVkVhgEdDn60+WEJH3XyjcCJf/Fs65S0X98Gaoq4RXvg9Hi3UhNipa0xWEAcEEkXdovRhjDuJY9CKSDFxtjCl3+gqc424ReRuYA+zq9sw7yQd5JQCcNt4KvUURkaeBs4BMEckH7gFiAIwxfwA+DXxVRJqAWmCRMcYATSJyG/Aq4AGWGGM298GfYOkJPvyNZpCc+VmoPQL/Ftj+iuarWfkHFfeKA5A6XOu/hgHBCP0x6wUV+EWodX4M53a2zBjjA+4Eljjt6UCNMabeGXM68GAI5x807+8sYdrwVDKSYvvi7S39EGPMtR30Pww83EbfcmB5T8zL0kN8+LDGtg8+zqng5+AnWqv1/Ps1iiZ5CIzMhY3PajphUNHHwKDRvTLtUNCh68YY0wS41stW4FljzGYRuU9E3Cias4DtIrIDGAr81GmfAqwRkfXoIu0DxpgtIf4bOqS2wcvafUeYb902FkvkU1ehycQCqa+C134E659u/9zVj0NsCpx0o79t0sWay6apVuPmD6zU2rB9HDLZGYLa/9+a9WKMuTvg+XPAc62c9yEwo5tz7Dar9pbR4PVZ/7zFEq68eKsufJ4VxCbk1+7SItrf2qDJwUD96wBHi9o/99B6XTiNT/O3TboY3vgJzFykFZ42/RPqKzqOuOlHDIgdQ099uJeU+GhOHpPR11OxWCxdIe8NePeXUBrE8l7ZHqgu0oLaLvWO0Fe3E9Xn80FJnhYPCWTIZFj0NCz4mZb+S3Vi4sPIoo94oV+zt4w3thVxy5njbVilxRKu1FeCrwne+mnHY48e1uNHv1PxhuAs+sp8dc9kTjy+b/LFGmopon5+CL6QSD8gooXeGMOD/9lOZnIcXzh9TF9Px2KxdAVvoyYHix+kbpOD69ofX3VYo2ZKdmiVJwiw6B2hb2qAT/7m/yEAHQ/HW/QtmXM9DJkG2X3ulQ6aiBb6NfuOsGpvGd84dwKJsTYdscUSlrjW+Km3abbIDc+0PbahRv3nJ92kYr/2z841KvR4tFg3P+18Ff51K+x5239uyU49diT0w2fDrR/qZqgwIaKFfu2+IwBcPmt4H8/EYrF0mXpHpNNGairgonYC944GlO3Lng6VTkika9E31ULDUTiyT18XbvSfW7JD7xqSIi9oI6KFfvPBSkYMSmBQoo2dt1jCFtcaj0+FIVM0tLEtqhz/fMpQ9anXHnGuUekfc7TIn5SsmdDvVGu+D/PG9xQRLvQVTBue2tfTsFgs3cEV6fg0FfqjhX4Bb6huPta16JOzHaEv19f1AUJfXeyvDlUYUHOmZEfHbpswJWKFvrq+iT0l1UwbntbxYIvF0n9xLfq4VMiaos+LtkHBx/BAjsa+uxyz6B2hr68Ab1MrFr0j9CU7oLFWfxCOHm494iYCiNgVym2FlRiDtegtlnDHtcbjUyFhkD4v3qruF18T5K+GYbO0/WihJhtLyPDXaK2r0GtEJ6iPvrpIk5IlDdHnRVvBONE31qIPLzYV6Idj2ggr9BZLWBPoukkbpeX5irbpJipo7rOvOgzJQyEqyi/0tUf0GhljAYEje6G2TIt3g/rpgw2tDFMiVug3H6wgIymW7NT4vp6KxWLpDoGuGxHImgx73/e7bIoDhP5ooQo9NBf6+kq18hMzoOATbR9zhua1KdwIe96FqBhID59EZZ0hgoW+kmnDU5EIXEG3WMIebxM8cz0UrO14bH2lCrKbEnjIZCjaDBjduFTcwqJPydbnx4S+TC36+FR11xxyNlwNytEQzE3PabKzeV85vu5rhBCRQt/Q5GPH4SqmWv+8xdI/qS6Crf+GPe91PNYVaRd3QTYhHWZ9VqNoqku1rU2LvkLvCJKzNI4enFj7Gdo/bDace09o/rZ+SEQKfV7RURq9xkbcWCz9lfoqPbYMj2yNunIVaZchk/U47iy16EGt+qYGqCltxaJ3fPRxKWrRA4hHC4iMP1eTlH16CURH7n6biIy62XLIWYi1Fr3F0j85JvRHgxhb2TxtcPYsjaCZutAv+sXb/P5116J3z6kp0/eLT/W7ZlJHqCto0gL/omwEE5lCf7CShBgPYwYn9fVULBZLa7ghk67gt0ddpVZ6cknOgu/tgtgkzVsTmwLF29X9An6LPsqjYl95EIxX7wpik7UvjHLJh4KIdN1sOVTB5GEpeKLsQqzF0i9xQyaDct1UNLfoQUUenCicSRpXf2xX7FD/uIR0KHfy2sSn+n8w0kZ2fe5hSMQJvTGGLQcrmTrMum0s7SMiS0SkSEQ2tdH/ORHZICIbReRDEZkV0LfXaV8nImt6b9YRQmddN3HtfJ+zJqtF75YPdC16UKF3E5jFpfp99GFUNCQUBCX0IrJARLaLSJ6IHFfLS0RGi8gbzpfibREZGdB3o4jsdB43tjw31BSU11JZ12QjbizB8CTQnoN2D3CmMWYGcD/wWIv+s40xs40xuT00v8ilo8XYzS/A8u+qa6auonnUTUuGTNb0Bcu/A55YSMry9yWka0ER0LuCZKdvgFn0HfroRcQDPAKcD+QDq0VkWYsi378CnjLG/FlEzgF+DtwgIhnAPUAuYIC1zrlHQv2HuGw+qLeE1qK3dIQx5l0RGdNO/4cBLz8CBpY69CSu0Lflo9/wD9jxHzj7R5rmoKXrJpBpV6nVnjYCRp/ePBY+IcOf3iAuFYbOgPl3wJTLQvN3hAnBWPRzgTxjzG5jTAOwFFjYYsxU4E3n+VsB/RcCrxtjyhxxf532Lahus+VgJVECk7Ot0FtCys3AKwGvDfCaiKwVkcV9NKfwxV2MdV033ibd7epStksXUN3NTe25btJGwCW/gvm3w6i5zfvcEEtwom6i4bx7IjLnfHsEI/QjgAMBr/OdtkDWA1c5z68EUkRkcJDnIiKLRWSNiKwpLm6neG8QbDlUydjMJFsf1hIyRORsVOi/H9A83xhzInAR8DUR+VQb54bssx1R1LdYjN3xH3jyEji0Qcv7le3R9vzVemzPom+PQKFv78ciwgnVYux3gDNF5BPgTKAA8AZ7sjHmMWNMrjEmNysrq+MT2mHLwUqm2o1SlhAhIjOBx4GFxphSt90YU+Aci4AX0Dvf4wjlZzuiOOa6cSx6N2Lm0HqtCuWt19f5ToqEUAh9e37+CCcYoS8AApeoRzptxzDGHDTGXGWMmQP8yGkrD+bcUFJe00BBea31z1tCgojkAM8DNxhjdgS0J4lIivscuABoNXLH0gau0DdWqwXvJi4r2qJuG5cCJ6Cpq9a4K/QS5Y+hH4AEI/SrgYkiMlZEYoFFwLLAASKSKSLute4EljjPXwUuEJF0EUlHvxCvhmbqx+OmJp5uUxNbgkBEngZWAJNEJF9EbhaRW0TkFmfI3cBg4HctwiiHAu+LyHpgFfCyMeY/vf4H9HfK9sDWl1rvC1yEbaz2V4I6vBlKHaEfPFHz2ED3Lfq4lIgsERgsHUbdGGOaROQ2VKA9wBJjzGYRuQ9YY4xZBpwF/FxEDPAu8DXn3DIRuR/9sQC4zxhT1gN/BwCbDqpVMN26bixBYIy5toP+LwFfaqV9NzDr+DMszVj1R1jzJ7jr8PF9gUJff1Tz2YAKffYMiI6HsZ+C0p3a3lW3yzGhH9iaEFQKBGPMcmB5i7a7A54/BzzXxrlL8Fv4PcrGggpGpieQnhS5yYkslrChvhKa6qCxDmJa1IWoq9SYd2+DLsi6Fn1NCexfARnjdCOUS3ddNwPYPw8RtjN2U0GFteYtlv5CY40eXWs9kPoq/w7WhiodE+XYnQVrVejd+q3i8ac86CzHLHor9BFBRW0j+0prmDHSCr3F0i9ocIW+onm7MWrtpwx3xlXrGDcpGcDg8f6yfvGpXfevuzVmrUUfGWx2/fMjrNBbLP2CRidGvqXQN1QDBlKH6ev6o+q6GTzen5AsYzykDoeYpK4vxILuko1NsRZ9X08gVGwqcBdiB/Z/qMXSb3At+toWrht3IfaYRe8sxsYPgqFOIZHB49WKz5zYfZGe8WmYcF73rhHmREw++o0FlQxPi2dwclxfT8VisYB/12tLi97dFev66OsrdXE2YRAMmQq73lQfPcCZ39MF3e5w2UPdOz8CiBih31xQYd02Fkt/4pjrpg2LPtWx6CsPAUZdNDM+A4kZWuYPYPIlvTLVSCciXDf1TV72llYzKTulr6disVhcGtqIujlm0TtiXuGmER4EmRPgjG8P6M1NPUFECP2Bshp8BsZl2dKBYUtFAZQf6HicJXxobCPqxrXoEwZp7Vc3X7wbIWMJOREh9LuK9RZxbObAzWUR1vh88Jcr4elFnTuvoQZqe6y0gaU7+HxtC71bRjAuBeKS9Uce1KK39AgRIfR7SlyhtxZ9j+NtCv01d74GJdvh8CZ/npNgePnb8KcLNS7b0r9wRR7atujjUnQjVKUj9Nai7zEiQuh3Fx8lMzmWtISYjgdbuk5FPjwwCra9HNrrfvgbSBysz7cvb3+si8+nOcxLtvt/HIq2QXVp++dZeodAoW8rvDIuVWPc3aia7sTLW9olIoR+T0k146zbpuc5sEq/wG/cp0LbHbb8C/5vFiz7Ouz7QMu7Zc8I/kfk8CaodfLj7XpDN9386Xx49vPWwu8PBNaCbS28MiYJolqkNrCumx4jYoTeum16gcNOyvXibbDlxfbHHlwHf7sGNraa6w7W/R2qDsMnf1NL7qQbYfKlsP8jOBpQickYWPc0PHUFrF/qF/E97+gxKQvy3tD51FfCvvdh+yvHv5+ld3Etek9c666bOCdCLs4x0KKiu57PxtIhYR9HX1HbSMnRhsiJuGmsU0EdmdvXMzmewk3+jILv/AKmXgFRUbDjNdj6L5j5Wf2yrv6TCjlGS8FNOK+5/7WpAfa8B3M+B2d8R2/d41I0Zvrtn8OFA/AAACAASURBVMOOV+DEz6tV+LfPqHgnpMPut+Djv8B1S2H325oLZeyZsO5vmvVw8AQtMPH63TDx/OZFoi29ixtamTq89fBKV+jdYiDxg2xIZQ8S9hZ9xC3EvvMLePxcLakWKp77orpI3IXU8gMBlvF78PDc4/2oL3wVXrq9eVvhRhg2C878vlr17zwAR/bCP2+GT/4Kf74M/ngObH4BTvkq3PSyXve9/9f8Ogc+0s0048/VfCcZY7V96HTdEbnyUfA2wocPq8hf8r/wnTy49CHY/yG8dAfs+1BFfsK5aj0WrIU5N8D592kO87VPhu7fz9J53KLfqcPVog90p9VX+ZOMuUJvF2J7lLC36HcX6wdqXFYE+Ogb6+DjP+vzD38LVz/e/WvWVcCm5wHj/8JtXQaXPwwn3qDWcMl2OLASTrhQzynJg/V/BwRO+7qKb3UpVB1UMZ52pfrF3/mFulMAvrZKf5waa2HaFf6FtdnXwco/6HHIFG3Le0Nv1cee0XyuIirUz1wP/70X1jwBUy6Hk2/W/twvaITGu7/U1+POgjFnQFQMGB/MuhaSh8Cpt8GIk7r/b2fpOo0BFr3xqfC7Vnxrrhu7ENujRIRF74kScjIS+3oq3WfLi1BTCiNPVnEOxQai/DWAUf/3ln/BztchIQM2PAM+r74+Ns5hzRIV4qhoWPGIth3eqMfsGSrIl/wv5JwK5fv0edYkmPkZ9bUHfmnPuQtiEuDRM+Gtn+sPwa43YNQp/i97IJMvhUkXw4qHtSjFefc27z/z+zAiV3OUj5mvQjHlMnUbpQzVuV34UxhxYvf/7Sxdx3XduLtfA+8YA4Xe9cvbhdgeJeyFfndxNaPSE4iNDtM/paFaLeHaI7D6ca2T+WmnINfKP3TtmisegacWqvV+YJX6ra/4PdzwIty2Ck7+kka67HhVfduI+tJBv6Dr/gpTF6p4fvI3teYLnYXY7Bl6jI6D656Bz/8LZl7T9lxSh8OtH8GUS9XV8/BcdQFNOKf18SJw0YPqkz/1a5rFMBBPjL7vjcv8t/vXPAFX/r5r/1aWnsHNc5M6Qo+BC7L1Vf6MlNZ10yuEvetmX1k1oweHoX++qQH+/hmNHjEBoYoLfgGDcmD61eq6OOWrkDayc9fe9E/1WR/8RF0yQ6apT3T82do/7Qp490F45Xv6IzDlctj1loZMbvyHfilP/pKK7bq/qoumrgKSsyEp0/8+8WnqPumI1OH643XSTbD8u9o28cK2xw8aBbdv0TuB1kjKhKT5QfxDhAf3LttMjEf40SVT+3oqocMNr3RzzrtCb4waNe5dn2vZW4u+RwnKDBaRBSKyXUTyROQHrfTniMhbIvKJiGwQkYud9jEiUisi65xHF03UtimsqGP4oDYEoT+z4xWNIsm9WUXw3Htg7ldgzvXaf85d+gOw/Hudu25jrX8hd/3T6pIZNbf5mCFT9c6h4gCMmqcRKvUVULJD7yKGTle3zJApKvirHoXNz/ut+a4y9lNwy/tw2xrInt7+2NjEHo/CEJElIlIkIpva6BcR+Y3zud8gIicG9N0oIjudx43dmce2wkrWH6joeGA4ccx142SodCNvqg6pv95NQ+y6bqxF36N0KPQi4gEeAS4CpgLXikhL0+Mu4FljzBxgEfC7gL5dxpjZzuOWEM0b0KyVJUcbGJYW3/HgvmDd0/DIKer68Hlh6efgxVvVqvn4L/oluOgXar2fcQdc/KB/cSp9NJx9J2x/Gba+1PZ7FG9vnu+l4GPwNUFiJqz9s9bjzDml+TkiuqAKMPECXRMAtdyLtuhipiuyF/1So1m8DR2LczB4Yvy1QPueJ4EF7fRfBEx0HouB3wOISAZwDzAPmAvcIyLpXZ1EYmw0NY09kFqiL2ms1kVy9w7QteiLturRDdONtYuxvUEwrpu5QJ4xZjeAiCwFFgJbAsYYwC0DkwYcDOUk2+JwRT0A2V0V+r3v6wesK5ZqU72zYOlpe8yuN6F4K/z7G7o4uM0R7GGzdEFy/h3tn3/KrbDhWXjpWzBsprp0vI26EBkVpe6ZPzq+7uyZcP3z6qoBOPfH8O9v6vOWFj1oDPuuN/VHJm0UxKWp1Z4yTNtcoqLgst/oj0GEVekxxrwrImPaGbIQeMoYY4CPRGSQiAwDzgJeN8aUAYjI6+gPxtNdmUdCrIeaem9XTu2/NNToXZkr4K7QF2/ToxuBZRdje4VgXDcjgMDwj3ynLZB7getFJB9YDnw9oG+s49J5R0RaxNMpIrJYRNaIyJri4uLWhrTKoYpagK5Z9HUV8PdF8PJ3OndeyU61yh8Y7fc3tzl2h6Zh3faSpg2YegUMnaG+ceNTsW0PTwx8+gn15z99Lbz3v/q+7/1K+3e9qcczv68LnKse1cXXwRNh5iL9kiUPhUGjj792+hj48ht65xAV5Y9SmXcLRMc2HxsVpdE0aS3/2yOetj77wXwngOA+24kxHmoaIkzoG6vVWm8p9EVb9W7TtfTdRVnruulRQhWqci3wpDFmJHAx8BcRiQIOATmOS+cO4O8iclwBSGPMY8aYXGNMblZWVtBvWlipyZC6JPRrn1S3RsHa5nk52qOxDv5yFWx+UUP5Nv1TLezWMEZ/FE68ASacr8J62f85Zc1E479dP2V7ZJ2gUSVFW+CNn2ibm1Zg7/vqTz/7h7qrdPXjuhlp1DyIidfQxE99Nzhf9/hz9AuY+4WOx1qCJpjPdmKsh5qGfuy68XXhR6ihGmIS9Y41LtUfXlm8zW/NAwyfrYbK+DaisCwhIRihLwBGBbwe6bQFcjPwLIAxZgUQD2QaY+qNMaVO+1pgF3BCdyftcqhChT47LWAxdvOLzXOltEZTA3z0B40n9zWqFRwMK/8AFfvh2qfhgv/RBaZ9H2q0ysdPQU2Zf2zlQbVqsibBdc/CrSvVahmZC5/9K1z8q+D/0Ann6jVueEFdMiXboXgH7F+pseQAp31DffW1RyBnnrblfhHmfjm49zj1NvjWRusrbU5bn/1gvhNBkxgXTW1jP7Xo1/4Z7hsMD+To7upgcV03oJ8pd7Ne8Xa/fx70rvXsH7a+p8ISMoIR+tXARBEZKyKx6GLrshZj9gPnAojIFFToi0Uky1nMRUTGoYtau0M1+cKKOlLio0mOc5YaqkvhHzfqZpv22PRP3eV56f+qv3vv+/6+2nJ1iTS2KEhcXapb+U9YAOPOVAskOl6zLW5Yql+CN+/3jy/ZocfME9T1ERNw1zHlUhgymU4x8Xx9z4kX6Ou3fw5NtX6hz5kHIx1f/Kh5nbs26BxjI2DTWWhZBnzeib45BagwxhwCXgUuEJF0ZxH2AqetSyTGeGj0Ghq93cwI2hPseUdruOacpsbM/o+CO6+xRjNUgl/oKw9qnpvOfvYt3aZDoTfGNAG3oR/krWh0zWYRuU9ELneGfRv4soisRxekbnIWsD4FbBCRdcBzwC3uAlYoOFRR29xtU+bkJT/4cfsnrnoUsqaoz3z4HBV6b6Pmdvl/k7Xa0RMX+SvfgG72aajWLfqgi0jjz3H87/cDopE07m7Wkp16zAzZDYwyeLwm79r8vL4efbq/78KfwklfUB+9pUNE5GlgBTBJRPJF5GYRuUVE3Oiw5ahhkgf8EbgVwPkM348aQauB+7rzuU6I1QX5XvfT/+UqXTtqj6KtuhD/6T/pvooPftP22OIdugP6aJF+V45Z9IP07rfYjbiZ0vY1LD1CUBumjDHL0Q99YNvdAc+3AKe3ct4/gX92c45tcqiirrnbxi1AcXCdulOO7NGIlQUPwNBp2le4STcSLfiF+q7HzNedpK/9WLf+z7kehp+oGRAfOxO+8B/AaN9JN6orxmXyJf5CGVf9URdp3/+13imU7FDfZPLQ0P/hJyzQu5ah09Xachk1t/UIG0urGGOu7aDfAF9ro28JsCQU80iM1a9hTUNT7xbPOfhx+1FfTQ36OT7hQjVs5i7WENzi7c2/By6fPAWH1unejcYaiHW8W0mZsOdd3ZQHzX30ll4hTPMGKIcq6hiWGmjRO16h+koozdNUuXve1ega12//yV/BE6t5WUAXRX2NsPL3Gi++8BFNovWlNzQy5unPwivfVzfNWXc2n8AJCzTEcvKler0Tb9Db2/ID+gXJnNgzm35c982YyNkdOpBJ7AuL3tvorOmUtz2mbJfuyRjibJuZu1i/B27+o0CMgS2OR/fIXmcx1nHdnPFt3Yex4mFIGtLcOLH0CmEr9A1NPkqO1jePoS/bpSIOGk2z81Un82IRLL0WyvZoMq9JF/s/bDnz1E+fMV4tf5chk3XR9Mg+J+b9W5oZMZCkTLX4Fzof/Pl36PH9X6vrJtRuG5fRp2k6gRO7tSHT0k9whb62N4W+xim52F5x9SJnq4xrgSdl6lrRnnePH1u4QRPcgd5JB7puhs2Ea/6s3zNrzfcJYZvrpqiqDmNahFaW7tKt+/lr1HdeuBHO+4mGNr7wFfjtSWC8anm7xKXAZ/+ikQDurlSX0afBlX/QcMZTWr2Dh1En+58PGuW36n2NPbcD1BOjoZqWiMDvuulFoa927nBbFgUJpGirinPgms+w2bD133onEBj7vuVfOjZ1hFr0jTUaXuky8Ty44XmNdLP0OmEr9IXHQisdoTdGLfaZn9HbTXcX6gkXqhUxbBa8+iP9gI87u/nFJl/S9hvN+LQ+gmX+HbooCz1n0VsiCv9ibC/G0rtCX3tEvzutuRiLturif2DE2PDZeizcoLmLwO+2GXO6Rtgc3qJVw1qWBhx3Vqj/CkuQhK3rxo2hP5bQrKZUE3NljPPv8kzL8cfsZoyFa/8OX3q9/QWo7uJa9WCF3hIUfeKjry7Ro6+p7Q2DRVuOd7Vkz9JjYAW0wg1a1WvK5Xr3fGSPttsasP2GMBZ6TX9wzKJ3I24Gj9eoGVBrvi/qUJ57j0bhWKG3BEHfCH3ApsLW/PQNNXqHPKRF/sLkLHXPBAr9ykfVTTPjGhV6N+12jN2X0V8IW9fNoYo6kmI9pLibpdyIm4xxevuYPhZmLeqbySUM8kf1WCwd4Proa/vCdQOOn35U8/6S7YBpffF02Cy/0B8t1hoGc27Qz336GP84a9H3G8JW6Iuq6hmSGo+4FnvZLi2iMWi0JuX65rq+naDFEiR9b9G3siBbvF2PrW1uGjYLtr8C9Uc1Z5S3AeZ9RfvSx/rHWYu+3xC2rpuKmkbSEwM2l5Tt1nS7LTMvWiz9nISYPvLRRznfn9ZcN+4O70Gjju8bNgswullw1WO6Q9zdQJU2Sg0usBZ9PyJshb68toFBiQGiXrrr+PqiFksYEBUlxMdE9X7UjZs9tbUQy8p8SBzcejnHYc6C7PNfBm89nPNjf190LKQ6pS+t0PcbwlfoaxoZ5G4X93l1g9LgCX07KYuliyTGRve+68bd59GaRV950F/YuyUpw9RFM3gCfOlNf5SbS7pT/8C6bvoNYeujr6hpJM113RRt1ZTAI3L7dlIWSxdJjPX07s7Y6hJdz4qKbt1HX1GgFc1aQwS+/KYKeWCMvUv6GNj7nrXo+xFhadE3en1U1TcxKMFNd7BGjyOt0FvCEy0+0ktC31CtO1eTszSzZKsWfX77FcUSM1oXefBH3liLvt8QlhZ9Za1WdRrkWvT5qzWFajAVmyyWfkhCbDQ1vVV8xI24ScrSkMiWPvr6o5o/vi3XTUfMWgQYSMnu1jQtoSP8hL5sD01b3gUyA4R+rebM7ovNURZLCEiM8fReHL27KzYpSw2klq6byoN67KrQp43UEpaWfkP4uW7WPsHQ/36DkVKkubvrKrQO5ciTOz7XYumnJMZ6qK7vbYs+s3XXTWW+HgdeMfiIJfyEvlrTq14StVLDKws+BgyMOKlv52WxdIOEWE/v1Y1t5rpJP951012L3tLvCD+hr9WKbRd7Vmp4pbsQa4XeEsYkxUb3Xhy9K/SJmeqjb2nRuyU0U4f3znwsPU5QQi8iC0Rku4jkicgPWunPEZG3ROQTEdkgIhcH9N3pnLddRC7s9oydggmzonaTUX8A8t6AzEnNc2NbLGFGQm9G3VSXQGyyFgZJSIe6St2L4lKZr9Z+dFzvzMfS43Qo9CLiAR4BLgKmAteKSIuUdtyFFg2fAywCfuecO9V5PQ1YAPzOuV7XqSmjMFnfPuWZq2H/Csj9YrcuabH0NW4cvZap7WGqi9U/D+qjx+hal0t7m6UsYUkwFv1cIM8Ys9sY0wAsBRa2GGOAVOd5GuA4+VgILDXG1Btj9gB5zvW6Tk0p++MnsYnxSGU+nH0XnHJLty5pGZgEcaf6axFZ5zx2iEh5QJ83oG9Zd+eSGOuhyWdo8Pq6e6mOqciHZCf0MSFdj3XlmpHS26ium7SRPT8PS68RTHjlCOBAwOt8YF6LMfcCr4nI14Ek4LyAcz9qce5xpoKILAYWA+TktLEbD8Dng7pyjiQm88f4r/LHSwfD9KuC+BMsluYE3Kmej34uV4vIMmPMFneMMeb2gPFfB+YEXKLWGDM7VPNJOJaq2EtcdA8WxmlqgIOfQO7Nzhs7Ls/d78BL34K5X4HKAhh7Rs/NwdLrhGox9lrgSWPMSOBi4C8iEvS1jTGPGWNyjTG5WVlZbQ+sKwfjo9ibTFHyFCvylu4QzJ1qINcCT/fUZJJ6MlVx5SEVclCrvakOchxbzbXoP3BqEK96FOorresmwghGjAtoXpVgpNMWyM3AswDGmBVAPJAZ5LnBU6MRN0XeJNISbTpiS7do7U61VXUTkdHAWODNgOZ4EVkjIh+JyBVtvYmILHbGrSkuLm5rWEDd2BAKvTGw/hl4ZB48dbkm/tu/QvtGneL8FY5Ff2QPTL3Cn77Aum4iimCEfjUwUUTGikgsurja0ie5HzgXQESmoEJf7IxbJCJxIjIWmAis6vJsndDKwoaE5rnoLZaeZRHwnDEmUIVHG2NygeuAh0Sk1RzZwd6tJjo56UOa2GzPO/DCYs1SKVGw4Rk4sFJThaQM1TGuRQ9w6m2w8Heanjh7ZujmYelzOvTRG2OaROQ24FXAAywxxmwWkfuANcaYZcC3gT+KyO3owuxNRsMHNovIs8AWoAn4WosvS+dwQisLGhKZkGCF3tItOnO3uQj4WmCDMabAOe4WkbdR//2uLs3kr5/mxDoDfJHqUMbSu+X+rv8n/OMmFfqGGph4gX+M66MfOkOTAorAd3fZdCIRRlC5bowxy4HlLdruDni+BTi9jXN/Cvy0G3P047huDtTFc5J13Vi6x7E7VVTgF6HWeTNEZDKQDqwIaEsHaowx9SKSiX72H+zyTKKiSajeA4TYoj+yT10zCYM00dgLTrm/nFP8Y6LjYOZnYdpVfnG3Ih9xhFdSM8d1U2ZS/EVHLJYuEOSdKugPwFLTPMB9CvCoiPhQ9+cDgdE6nSZ1OHH7PgSC8NE31UN9lT8Ovj3K9/mLgEy+VNMGN9Y0F3qAqx7rwqQt4UR4CX1NKSYqmqMk+DNXWixdpKM7Vef1va2c9yEwI2QTSRuBp76CBOo6ToPw/kOw5k/w7e0dW95H9sEQp7h3XDJMuxJ2vQmDJ4Zm3pawIcyEvoymuHSoESv0lsjBqbE6TMo6TmxWsh2OHtZHe/nefT4o3w+TFvjbLv6Vhk5GhV+KK0v3CK//8doyGmJ18SgtwfroLRGCkzwsW8o6dt1UFeqxtIN136OHtXD3oNH+tthEWwxkgBJeQl9TRm10GoC16C2Rg5P3fbiUUlPfgeum6pAey3a3P658nx7duHjLgCbshL7aoyl17GKsJWJIUYs+x3OkfYveGN3lClC2q3n7k5fC2if9bUf26tEKvYWwE/pSqqLUok+1Qm+JFGLiITGTkZ4jVLcn9HUV0FSrzwMt+sKNsPc92Payv+2IY9GnBW4VsAxUwkfojYHaMqokhdjoKGI84TN1i6VD0kYwylPG4cq6tse4/nkESgOEfsd/9Hhog7+tfB+kDNMfEcuAJ3zUsr4KfE0c9aQRa0XeEmmkjmS4lJF/pKbtMa5/Pnu6WvRuaP/2V/R4tBCOFunzI/uaL8RaBjTho5hO+gPXordYIorU4WT4Ssg/Utt28RHXoh89HxqrNbKmqhAOfgzjzta+wo16DNwsZRnwhI9iOrtiq6JSifHYLdqWCCNtBAneKmioprymsfUxVU49nzFOtpGy3bDjVX3+qe/qsXCDFg+pLLALsZZjhI/QO3luyq1Fb4lEjm2aKiX/SG3rY6oKIT4Nhk7T16W7YOu/dcF19GkwKEct+vL9YHzWdWM5RvgopiP0FaTYhVhL5OFsmhoupUSt+VPrG6KqDukCa1oOREXDqscg73WYc4OmQ8ieqQuyHz8FCIzqXtVOS+QQPoqZNgJmXEMpdjHWEoE4m6bujH6aaet+An+7Buoqm4+pKtSdrZ5otdYLN8DwE+GMO7Q/eyaU5sHKR2HGpzUPvcVCOAn9mPlw9eNUmkTrurFEHinDAJgatY89ySdqxad/f9MfWQOO0KvlT+YJEJMEVz8OHmdPSfYMwIC3Ac66s3fnb+nXhJ1iNnqNdd1YIo/oOBiUw07PeB4cfD+ccxdsfh7WL9V+n89v0QNc9AB88T8wOKCw1bBZepx9XfN2y4AnvLJXAg1en426sUQmN77EQy/uY0+FD06/HbYth9fvhsmXaB56X+Mxy7/ViJq0EVpNaqT1zVuaE3amcUOTj9hoT19Pw2IJPemjyRo8WGPpReDiB6G6CN590L9ZqqPskxPOg/jUnp+rJawIO4u+0esj1lr0lghlZHoCR+ubqKxtIm3ESTDnevjo91B+QAe4Fr3F0gmCsuhFZIGIbBeRPBH5QSv9vxaRdc5jh4iUB/R5A/qWtTy3s6hFH3Y3IhZLUIxMTwTggJsK4fz7Yfy5sOVFfZ1qhd7SeTq06EXEAzwCnA/kA6tFZFlgjUxjzO0B478OzAm4RK0xZnaoJtzo9dnFWEvEMjI9AYD8I7VMH5EGiRnwuWfhwCoo2gppI/t4hpZwJBjFnAvkGWN2G2MagKXAwnbGXws8HYrJtYaNurGEkiDuVm8SkeKAu9IvBfTdKCI7nceNoZjPKMeiPy652ai5cFJI3sIyAAnGRz8COBDwOh+Y19pAERkNjAXeDGiOF5E1QBPwgDHmxVbOWwwsBsjJyWl3MvXWdWMJEcHcrTo8Y4y5rcW5GcA9QC5ggLXOuUe6M6e0xBgGJ8Wy8/DR7lzGYmlGqBVzEfCcMSawesJoY0wucB3wkIgcF+BrjHnMGJNrjMnNyspq9w10MdYKvSUkdPZuNZALgdeNMWWOuL8OLOjgnKCYlJ3CtsNVobiUxQIEJ/QFQGCZmpFOW2ssooXbxhhT4Bx3A2/T3H/faRptHL0ldLR2tzqilXFXi8gGEXlORNzvQrDndppJ2SnsPFyFz9dGumKLpZMEI/SrgYkiMlZEYlExPy56RkQmA+nAioC2dBGJc55nAqcDLW+LO4WNurH0Mv8GxhhjZqJW+587c7KILBaRNSKypri4OKhzJg1NoabB64+8sVi6SYeKaYxpAm4DXgW2As8aYzaLyH0icnnA0EXAUtO8asIUYI2IrAfeQn30XRZ6n8/Q5LOLsZaQ0eHdqjGm1BhT77x8HDgp2HOd84N2S7pMyk4BYFuhdd9YQkNQG6aMMcuB5S3a7m7x+t5WzvsQmNGN+TWjwesDsBa9JVQcu1tFRXoRupZ0DBEZZoxxtqVyOWrsgBo+PxORdOf1BUBIMomdMFSFfnthFRdO62AnrMUSBGG1M7bRFXpr0VtCgDGmSUTcu1UPsMS9WwXWGGOWAd9w7lybgDLgJufcMhG5H/2xALjPGFMWinklxUWTk5HIdmvRW0JEmAm9eoWs68YSKjq6WzXG3EkblroxZgmwpCfmNSk7hW2FlR0PtFiCIKwUs6HJum4sA4PJ2SnsLa2hrtHb8WCLpQPCSjFd14216C2RzqTsFLw+Q16R3Thl6T5hpZj1Ta7Q2zh6S2QzZZimGt5y0LpvLN0nrITetejjrOvGEuGMy0wiIymWlXtCsr5rGeCElWJa141loCAizB2Twco9pX09FUsEEFaKaRdjLQOJeeMyyD9SS0F5bV9PxRLmhJViNliL3jKAmDs2A4CVu61Vb+keYaWYNo7eMpCYnJ1Kanw0K3dbP72le4SVYrquG7sYaxkIeKKEuWOtn97SfcJKMe1irGWgMW/sYPaW1nC4sq6vp2IJY8JKMRtsHL1lgDFvnPrpP7J+eks3CC+ht9krLQOMacPTSImPZsUuK/SWrhNWimmzV1oGGp4oYd7YwXxohd7SDcJKMW0cvWUgctr4wewvqyHfVpyydJGwUky7GGsZiJw2YTCAdd9YukxYKaZ/MTaspm2xdIsThqSQkRTLCrsga+kiQSmmiCwQke0ikiciP2il/9ciss557BCR8oC+G0Vkp/O4sTuTbTi2YcpG3VgGDlFRwqnjBrNiVynNSzJbLMHRodCLiAd4BLgImApcKyJTA8cYY243xsw2xswGfgs875ybAdwDzAPmAvcE1NjsNI1eH7GeKESs0FsGFqdNGMyhijq2H7blBS2dJxiLfi6QZ4zZbYxpAJYCC9sZfy3wtPP8QuB1Y0yZMeYI8DqwoKuTbWjyWWveMiC5YGo2UQIvbzjU8WCLpQXBCP0I4EDA63yn7ThEZDQwFnizM+eKyGIRWSMia4qLi9ucSKPXZyNuLAOSrJQ4Thk3mJc3HLLuG0unCbVqLgKeM8Z0qtClMeYxY0yuMSY3KyurzXGNXp9diLWEjCDWnu4QkS0iskFE3nAMGbfPG7Autaw35nvpzOHsLqlmyyFbdcrSOYJRzQJgVMDrkU5bayzC77bp7LkdUt9kLXpLaAhm7Qn4BMg1xswEngMeDOirddeljDGX98acF0zPxhMlvGTdN5ZOEoxqrgYmishYEYlFxfw4C0ZEJgPpwIqA5leBC0Qk3VmEvcBp6xKNXmN3xVpCRYdrT8aYt4wxKNCpwAAADcZJREFU7i6lj1BDpc/ISIrl9AmZvLThoHXfWDpFh6ppjGkCbkMFeivwrDFms4jcJyKBlswiYKkJ+AQaY8qA+9Efi9XAfU5bl2ho8lrXjSVUBL325HAz8ErA63hnXekjEbmirZOCXX8KlstnDedAWS0f7z/S7WtZBg7RwQwyxiwHlrdou7vF63vbOHcJsKSL82tGo9dY142l1xGR64Fc4MyA5tHGmAIRGQe8KSIbjTG7Wp5rjHkMeAwgNze322b4gunZ3PXiRp7/uICTRmd093KWAUJYqaYuxtrwSktICGr9SETOA34EXG6MqXfbjTEFznE38DYwpycn65IcF82F07J5acMh6ps6FfNgGcCEldDXN9moG0vI6HDtSUTmAI+iIl8U0J4uInHO80zgdGBLb038yjkjqKht5K1t3XcFWQYGYaWaNo7eEiqCXHv6JZAM/KNFGOUUYI2IrAfeAh4wxvSa0M+fkElmchzPrT3Q8WCLhSB99P2FhiYfsYlW6C2hoaO1J2PMeW2c9yEwo2dn1zbRniiuPyWHh/67k7e2F3H2pCF9NRVLmBBWqmkteotF+epZ45k4JJkfPr+RyrrGvp6OpZ8TVqrZ6DXWR2+xAHHRHn55zSwOV9bxq1e39/V0LP2csFLNBrsYa7EcY/aoQXz25ByWrjrA4cq6vp6OpR8TVqrZYF03FkszbjlzHE0+H396f09fT8XSjwkr1dR89DaO3mJxGT04iUtnDudvH+2josb66i2tE1ZCb103FsvxfPWs8VQ3ePnhixupsguzllYIK9W0UTcWy/FMGZbKt88/gVc2HmLBQ++xvdBWobI0J2xU0+czNurGYmmDr587kee+ehr1TT6+84/1eH02u6XFT9ioZqPPB2AteoulDU7MSefuy6aysaCCv360r6+nY+lHhI1qNnrVQrH56C2Wtrls5jDmT8jkV69uZ19pdV9Px9JPCBvVbGhSi95mr7RY2kZEuP+K6URFCQsf+YAP8kpskRJL+Ah9o9d13Xj6eCYWS/9mbGYSL37tdDKT4/jc4yuZce9rLHpsBbuLj/b11Cx9RNgIvbXoLZbgGZuZxAu3nsa9l03l6hNHsL2wioUPf8Brmwv7emqWPiB8hN5rF2Mtls6QEh/DTaeP5ScLp/Pvr89nbFYSi/+ylnuXbbZFSwYYYaOax1w3djHWYuk0I9MT+cctp3LTaWN48sO9LHz4AzbmV1DX6GXFrlJKjtZ3fBFL2BJUPnoRWQD8H+ABHjfGPNDKmM8A9wIGWG+Muc5p9wIbnWH7jTGXtzw3GPyuGyv0FktXiIv2cO/l0zhjYiZ3Pr+RK373ATEeoa7RR2Ksh8WfGsfiT40jMTasylRYgqDD/1ER8QCPAOcD+cBqEVkWWFFHRCYCdwKnG2OOiEhgJYRaY8zs7k600bpuLJaQcO6Uobx+RwaPvJVHfaOXU8cPZtn6gzz03508s/oAXz9nIjUNTVTUNvKl+eNIS4zp6ylbukkwP91zgTynCDIishRYSPMamV8GHjHGHAEIrK8ZKhqaNETMWvQWS/dJS4jhhxdPOfZ6wfRhrNlbxr3/3swPX9h4rH3Z+oP89to5TB+eRlSU4PUZBIiKskER4UQwQj8CCCxOmQ/MazHmBAAR+QB179xrjPmP0xcvImuAJrS25ost30BEFgOLAXJyclqdhH8x1n7ALJaeIHdMBv/62nw2FlQwYlAC+8uq+epfP+byhz8gNjqKxFgPFbWNCJCRFMcJQ5PJHZPB2ZOymD1qECL2u9lfCZUzLhqYCJwFjATeFZEZxphyYLQxpkBExgFvishGY8yuwJONMY8BjwHk5ua2urujscldjLVx9BZLT+GJEmaPGgRAVkocy795Bq9sKiS/rIaaBi/piTH4DBRX1bP5UAUPv7mT37yxk+zUeHIyEkmJj8YAyXHR3Dx/LGMyk3jigz2U1zTyuXk5TBya0rd/4AAlGKEvAEYFvB7ptAWSD6w0xjQCe0RkByr8q40xBQDGmN0i8jYwB9hFJ/n/7Z1rbBxXFcd/Z3a9G9sb24mdOIkDsanTVqYFmvJoEz6UViAaISpVoKYgVAk+oQJFvNQIiQ9IlSgfgEpIiAoI4qUWQlWsqCJqkwgEpWlCIRWtExryaN5P24mztte7c/hwb6yNiclu5O7eWZ+fNPLce2d2/zo+c+bOvWfnXu7RN1mP3phDrpVoICJZ4BfA7cA54AFVPeTbNgKfA0rAl1R1aw2l14SuXJbP3LFq1vbR8Sm2DZ1i+97TnLk4yYnRCVKR8MqbwwzuOU5LJkW+UCKTivj5i4e4YUkrPYta6F+So39pjj1HRth16Dy39LRz981LuWnZQno7W2nOuA7daH4KxA01GddPJYF+F7BaRPpwAX4D8KkZxzwLPAhsEpEu3FDOARFZBORVddLXrwO+ez1CL0/G2hi9MVdUkmiAC+TDqtovIhuAx4EHRGQAdy28E1gBvCAiN6rqvEpQb29u4v41K7l/zcor6scmi2z6y0EOn8/z2XV9LGtfwNO7jvDq0RGODo/zm4OHmZiKWZhNc3vvIv66/yyDe45Pn9/ZmiGKhDMXXdrnjd053t+3mPf1LmboxEV27D3N0rYst/S009PRTHtzE2OTRQQYWNFGVy7LqQsT5Avu3xGJkEkL6SgiFQktmRQtmTRNKaHZ7wPkC0WKsdK24Mobi6omemjqmoFeVYsi8gVgK67X8zNVfU1Evg3sVtVB3/YREXkd17v5uqqeE5G1wI9FJMbl7H9nxkVUMYWi5dEbc04liQb34dKGATYDPxR3xd8HPKWqk7in2P3+8/5WI+1Bk8um+eI9q6+o+/xdN0zvF0sxx0bGWd7eTCYdUYqVfScvcuDsGIfP5Tk6PM5UKWb10hyFYsyuw8M888oxfvXSm6Qi4QN9izk7VuDJPx+Yk1cyt2ZSZNIRw36VroUL0uSyaUqxMl4oMVYo0ppJ09HShAjEsRvmSkcCAigUYyVWJRUJkQgioAqlWInETWBf7VahuNewiz8nEkFVUdz5l+8vE4US+akSf/rah6rOhKpojF5VnwOem1H3rbJ9Bb7it/JjXgRurUrRLPR0NLP+1mXkspbja8wZlSQaTB/jOz2jQKevf2nGuT0zv6CSRIP5SDoVsaqzdbqcioSBFW0MrGib9ZypUszQiQv0dDTTmcsC7oZx7lKB0fEpctk0xZLyr+OjjOSn6G7LksumEXHZQoVSTCmOKRSViakSlwpFiiUlXyhx5uIkE8USPR3NpCPh2Mg4+UKJlAgt2RStmTRjk8XpyWj3mTHFsptMUypCgJIqsUKsSiRCSiBWVw+4yD4j4qd8NC+punZcgJeyoN/clKIlk0Kuo6+bmKi5tr+Ltf1d9ZZhGFVRSaKBURlNqYh3rey4oi6diuhuW0B324Lpurd3ttRaWvDYOIgxn6kk0WD6GBFJA+24SdlKzjWMILBAb8xnphMNRCSDm1wdnHHMIPCQ3/8EsN0PVQ4CG0Qk6xMVVgMv10i3YVRFYoZuDGOuqTDR4KfAL/1k63nczQB/3G9xE7dF4OH5lnFjJAcL9Ma8poJEgwngk7Oc+xjw2Fsq0DDmABu6MQzDaHAs0BuGYTQ4FugNwzAaHAv0hmEYDY6ohvUbDhE5AxyepbkLOFtDOZUSoq4QNUEYulap6pJaf2kCfTtETRCmrhA0zerXwQX6/4eI7FbV99Zbx0xC1BWiJghXV70J0S4haoIwdYWoqRwbujEMw2hwLNAbhmE0OEkL9E/WW8AshKgrRE0Qrq56E6JdQtQEYeoKUdM0iRqjNwzDMKonaT16wzAMo0os0BuGYTQ4iQn0IvJREdknIvtF5NE6aXibiOwQkddF5DURecTXLxaR50XkDf93UR20pUTkHyKyxZf7RGSnt9fT/jW8tdbUISKbRWSviAyJyJ0h2CokQvBrr8N8uzpNifLtRAT6skWc7wUGgAf94sy1pgh8VVUHgDuAh72OR4Ftqroa2ObLteYRYKis/DjwfVXtB4Zxi1zXmieAP6rqzcC7vb4QbBUEAfk1mG9XS7J8W1WD34A7ga1l5Y3AxgB0/QH4MLAPWO7rlgP7aqxjJc6x7ga24FakPAukr2a/GmlqBw7iJ/zL6utqq5C2UP3aazHfnl1T4nw7ET16rr6I8/8sxFxLRKQXuA3YCXSr6gnfdBLorrGcHwDfAGJf7gRGVLXoy/WwVx9wBtjkH7t/IiKt1N9WIRGcX4P5dgUkzreTEuiDQkRywO+BL6vqhfI2dbfzmuWsisjHgNOq+vdafWeFpIE1wI9U9TbgEjMeZWttK+PamG9XROJ8OymBPpiFmEWkCXch/FpVn/HVp0RkuW9fDpyuoaR1wMdF5BDwFO4R9wmgwy9mDfWx11HgqKru9OXNuIujnrYKjWD8Gsy3qyBxvp2UQF/JIs5vOSIiuDVEh1T1e2VN5QtIP4Qb36wJqrpRVVeqai/OLttV9dPADtxi1jXX5HWdBI6IyE2+6h7c+qp1s1WABOHXYL5dpa7k+Xa9JwmqmABZD/wb+A/wzTpp+CDucexV4J9+W48bN9wGvAG8ACyuk767gC1+/x3Ay8B+4HdAtg563gPs9vZ6FlgUiq1C2ULwa6/DfLs6PYnybXsFgmEYRoOTlKEbwzAM4zqxQG8YhtHgWKA3DMNocCzQG4ZhNDgW6A3DMBocC/SGYRgNjgV6wzCMBue/XvzVa8oIgj4AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(list(range(nb_epochs)), train_accs, label=\"Train\")\n",
        "plt.plot(list(range(nb_epochs)), val_accs, label=\"Val\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(list(range(nb_epochs)), train_losses, label=\"Train\")\n",
        "plt.plot(list(range(nb_epochs)), val_losses, label=\"Val\")\n",
        "plt.title(\"Loss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry9hgujofKMO"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Tu_xXdYLR-GQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04061ea7-b8f4-48d4-8d7d-1874df231483"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "state_dict = torch.load(\"vgg_best_param.pth\")\n",
        "vgg.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "939OxVuZJsCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90429f4f-c343-47af-cd2e-de0eff79919f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8640380693405847, 1.3545154936775519)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "test_acc, test_loss = eval_model(vgg, test_loader)\n",
        "test_acc, test_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF-ecOeESOBK"
      },
      "source": [
        "# II - Vgg with Pal\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aQp6olaRN6z"
      },
      "source": [
        "Now we will train to reproduce the best results of the paper using PAL. Consequently, we will use PAL on the 15th layer, with Grad\\*Input as attribution map and the half mean channel strategy. The other parameters will follow the paper, and thus will not change compared to part 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzPD9cMvRN6z"
      },
      "source": [
        "## Prepare dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIDGdf9YRN60"
      },
      "source": [
        "### Unzip priors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQmFZkQvSeuT"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"landmark.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"./landmark\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69CmLPTeSurv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27f09b64-af90-44ae-fe13-d401edb2236e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘landmark/train’: File exists\n",
            "mkdir: cannot create directory ‘landmark/test’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir landmark/train\n",
        "!mkdir landmark/test\n",
        "!mv landmark/landmark/train_* landmark/train\n",
        "!mv landmark/landmark/test_* landmark/test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mluVQasYRN61"
      },
      "source": [
        "### Create dataloaders\n",
        "The process is the same as in part I, with the added priors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ulx3aSxCS_3z"
      },
      "outputs": [],
      "source": [
        "class JoinImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, landmark_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.landmark_dir = landmark_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        land_path = os.path.join(self.landmark_dir, self.img_labels.iloc[idx, 0])\n",
        "        landmark = read_image(land_path)\n",
        "        landmark = landmark / 255.0\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, landmark, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P78LHeOuTjm3",
        "outputId": "336031bb-8180-48a7-b532-d420bcdaa4d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nb batches in train: 767\n"
          ]
        }
      ],
      "source": [
        "train_data = JoinImageDataset(\"train_list_label.csv\",\"./aligned/train\", \"./landmark/train\", transform=trans)\n",
        "train_loader = DataLoader(train_data, batch_size=16, shuffle=True, num_workers=4)\n",
        "print(f\"\\nNb batches in train: {len(train_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv1zFNLcT4xW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "test_data = JoinImageDataset(\"test_list_label.csv\",\"./aligned/test\",\"./landmark/test\", transform=trans)\n",
        "\n",
        "test_indices, val_indices = train_test_split(list(range(len(test_data.img_labels.Label))), test_size=0.5, stratify=test_data.img_labels.Label)\n",
        "\n",
        "val_data = torch.utils.data.Subset(test_data, val_indices)\n",
        "test_data = torch.utils.data.Subset(test_data, test_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCcVeomlUEx3",
        "outputId": "c341fe07-169d-4642-ae1a-ea0661b5183e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nb batches in test: 96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "test_loader = DataLoader(test_data, batch_size=16, shuffle=True, num_workers=4)\n",
        "print(f\"\\nNb batches in test: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlqNHILrUKMw",
        "outputId": "635f8367-424b-447f-cc6e-e9870fa75847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Nb batches in val: 96\n"
          ]
        }
      ],
      "source": [
        "val_loader = DataLoader(val_data, batch_size=16, shuffle=True, num_workers=4)\n",
        "print(f\"\\nNb batches in val: {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJNbYN58RN64"
      },
      "source": [
        "## Modified Vgg class\n",
        "The class now outputs the features computed by layer 15 as well in order to apply PAL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOSjJUATUOx4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class VggPal(Vgg):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(VggPal, self).__init__()\n",
        "  \n",
        "    def forward(self, x0):\n",
        "        x1 = self.conv1_1(x0)\n",
        "        x2 = self.relu1_1(x1)\n",
        "        x3 = self.conv1_2(x2)\n",
        "        x4 = self.relu1_2(x3)\n",
        "        x5 = self.pool1(x4)\n",
        "        x6 = self.conv2_1(x5)\n",
        "        x7 = self.relu2_1(x6)\n",
        "        x8 = self.conv2_2(x7)\n",
        "        x9 = self.relu2_2(x8)\n",
        "        x10 = self.pool2(x9)\n",
        "        x11 = self.conv3_1(x10)\n",
        "        x12 = self.relu3_1(x11)\n",
        "        x13 = self.conv3_2(x12)\n",
        "        x14 = self.relu3_2(x13)\n",
        "        x15 = self.conv3_3(x14)\n",
        "        x16 = self.relu3_3(x15)\n",
        "        x17 = self.pool3(x16)\n",
        "        x18 = self.conv4_1(x17)\n",
        "        x19 = self.relu4_1(x18)\n",
        "        x20 = self.conv4_2(x19)\n",
        "        x21 = self.relu4_2(x20)\n",
        "        x22 = self.conv4_3(x21)\n",
        "        x23 = self.relu4_3(x22)\n",
        "        x24 = self.pool4(x23)\n",
        "        x25 = self.conv5_1(x24)\n",
        "        x26 = self.relu5_1(x25)\n",
        "        x27 = self.conv5_2(x26)\n",
        "        x28 = self.relu5_2(x27)\n",
        "        x29 = self.conv5_3(x28)\n",
        "        x30 = self.relu5_3(x29)\n",
        "        x31_preflatten = self.pool5(x30)\n",
        "        x31 = x31_preflatten.view(x31_preflatten.size(0), -1)\n",
        "        x32 = self.fc6(x31)\n",
        "        x33 = self.relu6(x32)\n",
        "        x34 = self.dropout6(x33)\n",
        "        x35 = self.fc7(x34)\n",
        "        x36 = self.relu7(x35)\n",
        "        x37 = self.dropout7(x36)\n",
        "        x38 = self.fc8(x37)\n",
        "        \n",
        "        return x25,x38\n",
        "\n",
        "def vggpal_face(weights_path=None, **kwargs):\n",
        "    \"\"\"\n",
        "    load imported model instance\n",
        "\n",
        "    Args:\n",
        "        weights_path (str): If set, loads model weights from the given path\n",
        "    \"\"\"\n",
        "    model = VggPal()\n",
        "    if weights_path:\n",
        "        state_dict = torch.load(weights_path)\n",
        "        state_dict.pop(\"fc6.weight\")\n",
        "        state_dict.pop(\"fc6.bias\")\n",
        "        state_dict.pop(\"fc7.weight\")\n",
        "        state_dict.pop(\"fc7.bias\")\n",
        "        state_dict.pop(\"fc8.weight\")\n",
        "        state_dict.pop(\"fc8.bias\")\n",
        "        model.load_state_dict(state_dict, strict=False)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmsBDlm4RN65"
      },
      "source": [
        "### Load pretrained weights on vgg_face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJKrhFKVVgQM"
      },
      "outputs": [],
      "source": [
        "vggpal = vggpal_face(\"vgg_face_dag.pth\")\n",
        "vggpal = vggpal.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc_emjARRN66"
      },
      "source": [
        "## Definition of PAL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjeV_zDwZHx8"
      },
      "outputs": [],
      "source": [
        "def Grad(features, logits) :\n",
        "    logits_sum = logits.sum()\n",
        "    features.retain_grad()\n",
        "    logits_sum.backward(retain_graph=True)\n",
        "    return torch.abs(features.grad)\n",
        "\n",
        "def GradxInput(features, logits) :\n",
        "    Grad_val = Grad(features, logits)\n",
        "    return Grad_val * features\n",
        "\n",
        "def PAL(features, logits, prior, attribution_method, channel_strategy=None) :\n",
        "    attribution_map = attribution_method(features, logits)\n",
        "    \n",
        "    if channel_strategy == \"half_mean\" :\n",
        "        nb_class = attribution_map.shape[1]\n",
        "        attribution_map = attribution_map[:, int(nb_class/2):, :, :]\n",
        "    \n",
        "    if channel_strategy == \"half_mean\" or channel_strategy == \"mean\" :\n",
        "        attribution_map = attribution_map.mean(1).unsqueeze(1)\n",
        "    \n",
        "    attribution_map_resize = transforms.Resize(attribution_map.shape[-2:])\n",
        "    \n",
        "    prior = attribution_map_resize(prior)\n",
        "    \n",
        "    std = attribution_map.view(attribution_map.size(0), -1).std(1)\n",
        "    mean = attribution_map.view(attribution_map.size(0), -1).mean(1)\n",
        "    \n",
        "    \n",
        "    res = (attribution_map - mean.view(-1, 1, 1, 1)) / (std.view(-1, 1, 1, 1) + 1e-9)\n",
        "    res = res * prior.unsqueeze(1)\n",
        "    \n",
        "    res = res.view(res.size(0), -1).sum(1)\n",
        "    res = -res\n",
        "    return res.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puU0EGIdZOjx"
      },
      "outputs": [],
      "source": [
        "def tot_loss(features, prior, logits, y):\n",
        "    pa_loss = PAL(features, logits, prior, GradxInput, \"half_mean\")\n",
        "    ce_loss = cross_entropy(logits, y)\n",
        "    return pa_loss + ce_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJQ48Q0_RN68"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCv9Db4MRN69"
      },
      "source": [
        "### Initial evaluation on validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOqWGhSqZBDc"
      },
      "outputs": [],
      "source": [
        "def eval_modelpal(net, loader):\n",
        "  net.eval()\n",
        "  acc, loss = 0., 0.\n",
        "  c = 0\n",
        "  for x, prior, y in loader:\n",
        "    x, prior, y = x.to(device), prior.to(device),y.to(device)\n",
        "    features, logits = net(x.to(device))\n",
        "    loss += tot_loss(features, prior, logits, y).item()\n",
        "    preds = logits.argmax(dim=1)\n",
        "    acc += (preds.cpu().numpy() == y.cpu().numpy()).sum()\n",
        "    c += len(x)\n",
        "\n",
        "  acc /= c\n",
        "  loss /= len(loader)\n",
        "  net.train()\n",
        "  return acc, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYNlujThVo6i",
        "outputId": "f0f6579d-9ba3-4aa7-d679-fd68157323ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial accuracy/loss on val: 25.36/40341.8236\n"
          ]
        }
      ],
      "source": [
        "initial_acc, initial_loss = eval_modelpal(vggpal, val_loader)\n",
        "print(f\"Initial accuracy/loss on val: {round(100 * initial_acc, 2)}/{round(initial_loss, 4)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PisThvfWRN6-"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itbzcRpwV9Lb"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(vggpal.parameters(), lr=0.00005)\n",
        "scheduler = PolynomialLR(optimizer, total_iters=75, power=2)\n",
        "\n",
        "nb_epochs = 75\n",
        "\n",
        "train_accs, train_losses = [], []\n",
        "val_accs, val_losses = [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5f7XGWyWGZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af37e3d6-2b24-4db1-c852-ccad8a146640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 767/767 [05:13<00:00,  2.45batch/s, loss=9.31e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75, train acc/loss: 38.77/92826.6236, val acc/loss: 38.59/90788.7556, time 336s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 767/767 [05:13<00:00,  2.45batch/s, loss=7.7e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/75, train acc/loss: 38.91/91588.1951, val acc/loss: 38.59/91349.7791, time 334s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 767/767 [05:13<00:00,  2.45batch/s, loss=8.54e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/75, train acc/loss: 38.86/91583.1396, val acc/loss: 38.59/91956.8169, time 334s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 767/767 [05:13<00:00,  2.45batch/s, loss=8.86e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/75, train acc/loss: 38.88/91836.8825, val acc/loss: 38.59/92087.8805, time 334s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 767/767 [05:13<00:00,  2.45batch/s, loss=9.28e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/75, train acc/loss: 38.89/91725.0407, val acc/loss: 38.59/91027.6633, time 334s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 767/767 [05:13<00:00,  2.45batch/s, loss=8.92e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/75, train acc/loss: 38.86/91587.4653, val acc/loss: 38.59/91490.6176, time 334s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 767/767 [05:13<00:00,  2.45batch/s, loss=8.37e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/75, train acc/loss: 38.9/91802.0658, val acc/loss: 38.59/90996.9875, time 334s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 767/767 [05:13<00:00,  2.44batch/s, loss=9.05e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/75, train acc/loss: 38.86/91982.7924, val acc/loss: 38.59/91327.6587, time 334s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 767/767 [05:13<00:00,  2.44batch/s, loss=8.87e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/75, train acc/loss: 38.92/91768.6697, val acc/loss: 38.59/91635.3411, time 334s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 767/767 [05:14<00:00,  2.44batch/s, loss=8.51e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/75, train acc/loss: 38.9/91817.9431, val acc/loss: 38.59/91605.0011, time 334s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 767/767 [05:14<00:00,  2.44batch/s, loss=1.06e+5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/75, train acc/loss: 38.89/91710.9766, val acc/loss: 38.59/91369.2567, time 335s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 767/767 [05:14<00:00,  2.44batch/s, loss=9.07e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/75, train acc/loss: 38.9/91896.9998, val acc/loss: 38.59/91639.8052, time 335s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 767/767 [05:14<00:00,  2.44batch/s, loss=7.81e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/75, train acc/loss: 38.88/91562.4983, val acc/loss: 38.59/91141.4811, time 334s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 767/767 [05:14<00:00,  2.44batch/s, loss=8.21e+4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/75, train acc/loss: 38.91/91854.6084, val acc/loss: 38.59/91688.7273, time 335s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 185/767 [01:15<03:57,  2.45batch/s, loss=1.01e+5]"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "best_acc = 0\n",
        "for epoch in range(nb_epochs):\n",
        "  with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "    start = time.time()\n",
        "    running_acc, running_loss = 0., 0.\n",
        "    c = 0\n",
        "    for x, prior, y in tepoch:\n",
        "      x, prior, y = x.to(device), prior.to(device),y.to(device)\n",
        "\n",
        "      optimizer.zero_grad()  # Clear previous gradients\n",
        "      features, logits = vggpal(x)\n",
        "      loss = tot_loss(features, prior, logits, y)\n",
        "      vggpal.zero_grad() # Remove gradients of PAL\n",
        "      loss.backward()  # Compute gradients\n",
        "      optimizer.step()  # Update weights with gradients\n",
        "\n",
        "      running_acc += (logits.argmax(dim=1).cpu().numpy() == y.cpu().numpy()).sum()\n",
        "      running_loss += loss.item()\n",
        "      c += len(x)\n",
        "      tepoch.set_postfix(loss=loss.item())\n",
        "    \n",
        "    scheduler.step()\n",
        "\n",
        "    train_acc, train_loss = running_acc / c, running_loss / len(train_loader)\n",
        "    train_accs.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "    \n",
        "    val_acc, val_loss = eval_modelpal(vggpal, val_loader)\n",
        "    if val_acc > best_acc:\n",
        "      best_acc = val_acc\n",
        "      torch.save(vggpal.state_dict(),\"vggpal_best_param.pth\")\n",
        "    val_accs.append(val_acc)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1}/{nb_epochs}, \"\n",
        "        f\"train acc/loss: {round(100 * train_acc, 2)}/{round(train_loss, 4)}, \"\n",
        "        f\"val acc/loss: {round(100 * val_acc, 2)}/{round(val_loss, 4)}, \"\n",
        "        f\"time {int(time.time() - start)}s\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3DdRcYgXx5H"
      },
      "outputs": [],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(list(range(nb_epochs)), train_accs, label=\"Train\")\n",
        "plt.plot(list(range(nb_epochs)), val_accs, label=\"Val\")\n",
        "plt.title(\"Accuracy\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(list(range(nb_epochs)), train_losses, label=\"Train\")\n",
        "plt.plot(list(range(nb_epochs)), val_losses, label=\"Val\")\n",
        "plt.title(\"Loss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiizdxWxRN7B"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdM_4qN_X0T3"
      },
      "outputs": [],
      "source": [
        "state_dict = torch.load(\"vggpal_best_param.pth\")\n",
        "vgg.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OwF7dnQX4Lt"
      },
      "outputs": [],
      "source": [
        "test_acc, test_loss = eval_modelpal(vgg, test_loader)\n",
        "test_acc, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t1FVH7rsTEKp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}