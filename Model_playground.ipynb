{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e55a225-8570-45ac-b1ec-31300c0ea11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b617e65c-2b8a-4c3a-9d71-21591fc0137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "981e4c05-682a-4378-935a-bcd237e81280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (c1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (p1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (p2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (c3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (p3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (l1): Linear(in_features=1024, out_features=1000, bias=True)\n",
      "  (l2): Linear(in_features=1000, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()  # Important, otherwise will throw an error\n",
    "\n",
    "    self.c1 = torch.nn.Conv2d(3, 32, 5, padding=2)\n",
    "    self.p1 = torch.nn.MaxPool2d(2)\n",
    "    \n",
    "    self.c2 = torch.nn.Conv2d(32, 64, 5, padding=2)\n",
    "    self.p2 = torch.nn.MaxPool2d(2)\n",
    "\n",
    "    self.c3 = torch.nn.Conv2d(64, 64, 5, padding=2)\n",
    "    self.p3 = torch.nn.MaxPool2d(2)\n",
    "    \n",
    "    self.l1 = torch.nn.Linear(4 * 4 * 64, 1000)\n",
    "    self.l2 = torch.nn.Linear(1000, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \n",
    "    c1_i = x\n",
    "    c1_o = self.c1(c1_i)\n",
    "    x = F.relu(c1_o)\n",
    "    x = self.p1(x)\n",
    "    \n",
    "    #c1_i.retain_grad()\n",
    "    #c1_o.retain_grad()\n",
    "    \n",
    "    c2_i = x\n",
    "    c2_o = self.c2(c2_i)\n",
    "    x = F.relu(c2_o)\n",
    "    x = self.p2(x)\n",
    "    \n",
    "    c3_i = x\n",
    "    c3_o = self.c3(c3_i)\n",
    "    x = F.relu(c3_o)\n",
    "    x = self.p3(x)\n",
    "    \n",
    "    x = torch.flatten(x, start_dim=1)\n",
    "    \n",
    "    x = F.relu(self.l1(x))\n",
    "    \n",
    "    x = self.l2(x)\n",
    "    \n",
    "    return c1_i, c1_o, c2_i, c2_o, c3_i, c3_o, x\n",
    "\n",
    "\n",
    "net = CNN()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "2f2993e7-c06c-4ecd-9850-a9dc6c8eb88d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0234, -0.0230,  0.0264, -0.0998, -0.0421,  0.0030, -0.0220,  0.0259,\n",
       "         -0.0675, -0.0316],\n",
       "        [ 0.0126, -0.0407,  0.0282, -0.0782, -0.0266,  0.0091, -0.0212,  0.0132,\n",
       "         -0.0635, -0.0215]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_input = torch.randn(2, 3, 32, 32)\n",
    "\n",
    "\n",
    "c1_i, c1_o, c2_i, c2_o, c3_i, c3_o, outputs = net(fake_input)\n",
    "net.zero_grad()\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "00090efb-a1ba-4f07-8576-f04ec609e44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grad(inputs, outputs) :\n",
    "    outputs_sum = outputs.sum()\n",
    "    \n",
    "    inputs.retain_grad()\n",
    "    outputs.retain_grad()\n",
    "    outputs_sum.backward(retain_graph=True)\n",
    "    return torch.abs(inputs.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba59663-922c-4415-951f-d6e1a5e2fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Grad(c2_i, c2_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37cfeebe-d7f9-4abd-8736-9cb38d77d5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradxInput(inputs, outputs) :\n",
    "    Grad_val = Grad(inputs, outputs)\n",
    "    return Grad_val * inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1b502b-b75d-4578-bd2e-fe1d776a5138",
   "metadata": {},
   "outputs": [],
   "source": [
    "GradxInput(c2_i, c2_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "1fb6e6cb-3a5f-446e-85fb-644a0d716695",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_prior = torch.randn(2, 64, 64, requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "21af8630-1156-4a59-bc1d-8bdc325e8578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pal_loss(inputs, outputs, prior, attribution_method, channel_strategy=None) :\n",
    "    attribution_map = attribution_method(inputs, outputs)\n",
    "    \n",
    "    if channel_strategy == \"half_mean\" :\n",
    "        nb_class = attribution_map.shape[1]\n",
    "        attribution_map[:, nb_class/2:, :, :]\n",
    "    \n",
    "    if channel_strategy == \"half_mean\" or channel_strategy == \"mean\" :\n",
    "        attribution_map = attribution_map.mean(1).unsqueeze(1)\n",
    "    \n",
    "    attribution_map_resize = transforms.Resize(attribution_map.shape[-2:])\n",
    "    \n",
    "    prior = attribution_map_resize(prior)\n",
    "    \n",
    "    std = attribution_map.view(attribution_map.size(0), -1).std(1)\n",
    "    mean = attribution_map.view(attribution_map.size(0), -1).mean(1)\n",
    "    \n",
    "    \n",
    "    res = (attribution_map - mean.view(-1, 1, 1, 1)) / std.view(-1, 1, 1, 1)\n",
    "    res = res * prior.unsqueeze(1)\n",
    "    \n",
    "    res = res.view(res.size(0), -1).sum(1)\n",
    "    res = -res\n",
    "    return res.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0c7376ac-0fe6-44fe-96e8-1647040cf1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pal_loss(c2_i, c2_o, fake_prior, GradxInput)\n",
    "net.zero_grad()\n",
    "loss.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
